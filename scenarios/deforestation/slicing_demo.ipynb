{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZecevFL1MrY"
   },
   "source": [
    "## How to contribute a slicing function for Xingu\n",
    "\n",
    "Slicing functions define a spatial and temporal area that can be used to evaluate automatically generated models in Xingu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9luLYMd2taB"
   },
   "source": [
    "### Login GEE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "5gn61qx81C2a",
    "outputId": "c1393cf0-a080-4ab8-f6db-2225d2a8e100"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jr/anaconda3/envs/tf2/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code\n",
      "\n",
      "The authorization workflow will generate a code, which you should paste in the box below. \n",
      "Enter verification code: 4/wgEtndJtNF8ELjeBMJL-NeQ7741dGsauO8ZXNkm7vrTFGDOGmMDunso\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "# Import the Earth Engine API and initialize it.\n",
    "import ee\n",
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "# Initialize the library.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7V8yzem22-Fk"
   },
   "source": [
    "## Specify base maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6b5A2G8o3Lr-"
   },
   "outputs": [],
   "source": [
    "# Use these bands for prediction.\n",
    "bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "# Use Landsat 8 surface reflectance data.\n",
    "l8sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "ndvi = ee.ImageCollection('LANDSAT/LC08/C01/T1_32DAY_NDVI')\n",
    "hansen = ee.Image(\"UMD/hansen/global_forest_change_2018_v1_6\")\n",
    "#l7sr = ee.ImageCollection('LANDSAT/LC07/C01/T1_SR')\n",
    "#sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR').filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n",
    "\n",
    "## get nighttime lights\n",
    "nightlight_col = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG')\n",
    "\n",
    "def maskS2clouds(image):\n",
    "  qa = image.select('QA60');\n",
    "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "  cloudBitMask = 1 << 10;\n",
    "  cirrusBitMask = 1 << 11;\n",
    "\n",
    "  # Both flags should be set to zero, indicating clear conditions.\n",
    "  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0));\n",
    "\n",
    "  return image.updateMask(mask).divide(10000);\n",
    "                                                 \n",
    "                                                          \n",
    "## Cloud masking function.\n",
    "def maskL8sr(image):\n",
    "  cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
    "  cloudsBitMask = ee.Number(2).pow(5).int()\n",
    "  qa = image.select('pixel_qa')\n",
    "  mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
    "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
    "  return image.updateMask(mask).select(bands).divide(10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get median composites for years 2013-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n"
     ]
    }
   ],
   "source": [
    "images_per_year = dict()\n",
    "for year in range(2013, 2019):\n",
    "    print(year)\n",
    "    images_per_year[year] = {'ls8sr':  l8sr.filterDate('{}-01-01'.format(year), '{}-12-31'.format(year)).map(maskL8sr).median()}\n",
    "    images_per_year[year]['nightlight'] = nightlight_col.filterDate('{}-01-01'.format(year), '{}-12-31'.format(year)).median()\n",
    "    images_per_year[year]['ndvi'] = ndvi.filterDate('{}-01-01'.format(year), '{}-12-31'.format(year)).median()\n",
    "    lossYear = hansen.select(['lossyear'])\n",
    "    images_per_year[year]['hansen'] = lossYear.gt(year - 2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DY2qIpku7m_l"
   },
   "source": [
    "## Get all available scenario regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "wkVbAtaVSevN",
    "outputId": "d2c25ed7-3083-4734-862c-1c5772cd2415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 16 scenario regions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geojson\n",
    "base_dir = os.getcwd()\n",
    "all_geojson_paths = [os.path.join(base_dir, x) for x in os.listdir(base_dir) if x.endswith('.geojson')]\n",
    "all_geojsons = []\n",
    "for geojson_path in all_geojson_paths:\n",
    "    with open(geojson_path) as f:\n",
    "        gj = geojson.load(f)\n",
    "        all_geojsons.append(gj)\n",
    "print('found {} scenario regions'.format(len(all_geojsons)))\n",
    "#all_geojsons = sorted(all_geojsons)\n",
    "import random\n",
    "random.seed(123)\n",
    "random.shuffle(all_geojsons)\n",
    "train_range = round(0.7 * len(all_geojsons))\n",
    "val_range = round(0.8 * len(all_geojsons))\n",
    "train_regions = all_geojsons[:train_range]\n",
    "val_regions = all_geojsons[train_range:val_range]\n",
    "test_regions = all_geojsons[val_range:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sample train region\n",
    "#train_region = train_regions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "o-Mz2Kfl7uaf",
    "outputId": "7116c3c8-373a-485f-9c08-e5ae9ced2c8a"
   },
   "outputs": [],
   "source": [
    "def get_coordinates_for_region(region):\n",
    "    region = train_region[\"coordinates\"][0]\n",
    "    region_inv = [[x[1],x[0]] for x in region]\n",
    "    x_center = sum(x[0] for x in region_inv) / len(region_inv)\n",
    "    y_center = sum(x[1] for x in region_inv) / len(region_inv)\n",
    "    edges = region_inv\n",
    "    center_coords = [x_center, y_center]\n",
    "    return edges, center_coords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7lrS3gZ6dCm"
   },
   "source": [
    "## This is how we visualize it in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_img(image, target_geometry):\n",
    "    minMax = image.reduceRegion(reducer= ee.Reducer.minMax(), geometry= target_geometry,scale= 30, maxPixels= 10e9,   # tileScale: 16\n",
    "    );\n",
    "    def scale(name):\n",
    "        name = ee.String(name);\n",
    "        #print('band name: {}'.format(name))\n",
    "        band = image.select(name);\n",
    "        \n",
    "        return band.unitScale(ee.Number(minMax.get(name.cat('_min'))), ee.Number(minMax.get(name.cat('_max'))))\n",
    "                    # eventually multiply by 100 to get range 0-100\n",
    "                    #.multiply(100); \n",
    "    scaled_bands = image.bandNames().map(scale)\n",
    "    unitScale = ee.ImageCollection.fromImages(scaled_bands)\n",
    "    unitScale_bands = unitScale.toBands().rename(image.bandNames());\n",
    "    \n",
    "#    meanDict = unitScale_bands.reduceRegion(reducer=  ee.Reducer.mean(), geometry =target_geometry, scale=30 )\n",
    "#    minMaxDict = unitScale_bands.reduceRegion(reducer=  ee.Reducer.minMax(), geometry =target_geometry, scale=30 )\n",
    "#    print(meanDict.getInfo())\n",
    "#    print(minMaxDict.getInfo())\n",
    "    \n",
    "    return unitScale_bands\n",
    "\n",
    "def getMinMax(image, target_geometry):\n",
    "    minMaxDict = image.reduceRegion(reducer=  ee.Reducer.minMax(), geometry=target_geometry, scale=30 )\n",
    "    print(minMaxDict.getInfo())\n",
    "\n",
    "def maskGeometry(image, geometry):\n",
    "   mask =  ee.Image.constant(1).clip(geometry).mask()\n",
    "   return image.updateMask(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import folium\n",
    "\n",
    "def display_img(image, center_location, value_name, mask_region):\n",
    "    mapIdDict = image.getMapId({'bands': [value_name], 'min': 0.0, 'max': 1})\n",
    "    folium_map = folium.Map(location=center_location)\n",
    "    folium.TileLayer(\n",
    "        tiles=mapIdDict['tile_fetcher'].url_format,\n",
    "        attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "        overlay=True,\n",
    "        name='median composite',\n",
    "      ).add_to(folium_map)\n",
    "    folium_map.add_child(folium.LayerControl())\n",
    "\n",
    "    line_color='red'\n",
    "    fill_color='red'\n",
    "    weight=2\n",
    "    text='Selected Region'\n",
    "    \n",
    "    folium_map.add_child(folium.vector_layers.Polygon(locations=mask_region, color=line_color, fill_color=fill_color,\n",
    "                                                  weight=weight, popup=(folium.Popup(text))))\n",
    "\n",
    "    return folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sv7YibOt3H0b"
   },
   "source": [
    "### We use folium to visualize the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HJ87-5r86gNl",
    "outputId": "44519284-08ff-4517-b4d2-372d8944e4a9"
   },
   "outputs": [],
   "source": [
    "def compute_and_display_yeardiff(images_per_year, year, img_type, value_name, region):\n",
    "    image = images_per_year[year][img_type]\n",
    "    img_cur = maskGeometry(images_per_year[year][img_type], region)\n",
    "    img_old = maskGeometry(images_per_year[year-1][img_type], region)\n",
    "    imgs_diff = img_cur.select(value_name).subtract(img_old.select(value_name))\n",
    "    #normalized_diff\n",
    "    #imgs_normdiff = imgs_diff.divide(img_cur.select(value_name).add(img_old.select(value_name)))\n",
    "\n",
    "    #Define a kernel.\n",
    "    #kernel = ee.Kernel.circle(radius= 15);\n",
    "    #dilated = maskGeometry(imgs_normdiff.focal_max(kernel= kernel, iterations= 2), region)\n",
    "    #roi_image = maskGeometry(image, region)\n",
    "    scaled_img = get_scaled_img(imgs_diff, region)\n",
    "    edges, center_coords = get_coordinates_for_region(region)\n",
    "    \n",
    "    folium_map = display_img(scaled_img, center_location=center_coords, value_name=value_name, mask_region=edges)\n",
    "    return folium_map, scaled_img\n",
    "\n",
    "def compute_and_display_year(images_per_year, year, img_type, value_name, region):\n",
    "    image = images_per_year[year][img_type]\n",
    "    img_cur = maskGeometry(images_per_year[year][img_type], region)\n",
    "    scaled_img = get_scaled_img(img_cur, region)\n",
    "    edges, center_coords = get_coordinates_for_region(region)\n",
    "    folium_map = display_img(scaled_img, center_location=center_coords, value_name=value_name, mask_region=edges)\n",
    "    return folium_map, scaled_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display year for demo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7ff260493510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2016\n",
    "train_region = train_regions[0]\n",
    "folium_map, scaled_img = compute_and_display_year(images_per_year, year=year, img_type='hansen', value_name='lossyear', region=train_region)\n",
    "#folium_map, scaled_yeardiff = compute_and_display_yeardiff(images_per_year, year=year, img_type='ndvi', value_name='NDVI', region=train_region)\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect \"year difference\" features for NDVI and nightlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HJ87-5r86gNl",
    "outputId": "44519284-08ff-4517-b4d2-372d8944e4a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting features for region 1 out of 11\n",
      "collecting features for region 2 out of 11\n",
      "collecting features for region 3 out of 11\n",
      "collecting features for region 4 out of 11\n",
      "collecting features for region 5 out of 11\n",
      "collecting features for region 6 out of 11\n",
      "collecting features for region 7 out of 11\n",
      "collecting features for region 8 out of 11\n",
      "collecting features for region 9 out of 11\n",
      "collecting features for region 10 out of 11\n",
      "collecting features for region 11 out of 11\n",
      "collecting features for region 1 out of 2\n",
      "collecting features for region 2 out of 2\n",
      "collecting features for region 1 out of 3\n",
      "collecting features for region 2 out of 3\n",
      "collecting features for region 3 out of 3\n"
     ]
    }
   ],
   "source": [
    "#print(folium.__version__)\n",
    "\n",
    "datasets = dict()\n",
    "\n",
    "set_types = ['train', 'val', 'eval']\n",
    "set_regions = [train_regions, val_regions, test_regions]\n",
    "\n",
    "for set_type, regions in zip(set_types, set_regions):\n",
    "    for i, region in enumerate(regions):\n",
    "        print('collecting features for region {} out of {}'.format(i+1, len(regions)))\n",
    "        #print(region)\n",
    "        scaled_features = dict()\n",
    "        gt_labels = dict()\n",
    "        \n",
    "        for year in range(2015, 2018):\n",
    "            if year not in scaled_features:\n",
    "                scaled_features[year] = dict()\n",
    "            for img_type, value_name in zip(['ndvi', 'nightlight'], ['NDVI', 'avg_rad']):\n",
    "                if img_type not in scaled_features[year]:\n",
    "                    scaled_features[year][img_type] = dict()\n",
    "\n",
    "                _, scaled_yeardiff = compute_and_display_yeardiff(images_per_year, year=year, img_type=img_type, value_name=value_name, region=region)\n",
    "                _, scaled_img = compute_and_display_year(images_per_year, year=year, img_type=img_type, value_name=value_name, region=region)\n",
    "                scaled_features[year][img_type] = {'default': scaled_img, 'yeardiff': scaled_yeardiff}\n",
    "            #yeardiff\n",
    "            folium_map, scaled_img = compute_and_display_year(images_per_year, year=year, img_type='hansen', value_name='lossyear', region=region)\n",
    "            gt_labels[year] = scaled_img\n",
    "            if set_type not in datasets:\n",
    "                datasets[set_type] = dict()\n",
    "            datasets[set_type][i] = {'features': scaled_features, 'labels': gt_labels}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge features and labels for all regions of their respective train/val/test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_type, regions in zip(set_types, set_regions):\n",
    "    num_regions = len(regions)\n",
    "    datasets[set_type]['merged'] = {'features': dict(), 'labels': dict()}\n",
    "    for year in range(2015, 2018):\n",
    "        datasets[set_type]['merged']['features'][year] = dict() \n",
    "        datasets[set_type]['merged']['labels'][year] = dict() \n",
    "        for img_type, value_name in zip(['ndvi', 'nightlight'], ['NDVI', 'avg_rad']):\n",
    "            datasets[set_type]['merged']['features'][year][img_type] = dict() \n",
    "            #for i, region in enumerate(regions):\n",
    "            for feature_type in ['default', 'yeardiff']:\n",
    "                new_band_name = value_name + '_' + feature_type\n",
    "                datasets[set_type]['merged']['features'][year][img_type][feature_type] = ee.ImageCollection([datasets[set_type][i]['features'][year][img_type][feature_type].select([value_name], [new_band_name]) for i in range(num_regions)])\n",
    "                #datasets[set_type]['merged']['features'][year][img_type][feature_type] = ee.ImageCollection([datasets[set_type][i]['features'][year][img_type][feature_type] for i in range(num_regions)])\n",
    "        datasets[set_type]['merged']['labels'][year] = ee.ImageCollection([datasets[set_type][i]['labels'][year].select(['lossyear'],['gt_lossyear']) for i in range(num_regions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xebx9Bm88hVo"
   },
   "source": [
    "    ## Inspect training and validation polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7ff26043a5d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingPolys = ee.FeatureCollection(train_regions)\n",
    "evalPolys = ee.FeatureCollection(test_regions)\n",
    "valPolys = ee.FeatureCollection(val_regions)\n",
    "\n",
    "polyImage = ee.Image(0).byte().paint(trainingPolys, 1).paint(valPolys, 2).paint(evalPolys, 3)\n",
    "polyImage = polyImage.updateMask(polyImage)\n",
    "\n",
    "mapid = polyImage.getMapId({'min': 1, 'max': 3, 'palette': ['red', 'green', 'blue']})\n",
    "map = folium.Map(zoom_start=5)\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name='training polygons',\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "band names: ['ndvi_default', 'ndvi_yeardiff', 'nightlight_default', 'nightlight_yeardiff', 'class']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7ff2633710d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "##Create a demo feature from the training data\n",
    "#imageStack = ee.Image.cat([\n",
    "#     datasets['train']['merged']['features'][2016]['ndvi']['default'],\n",
    "#     datasets['train']['merged']['features'][2016]['ndvi']['yeardiff'],\n",
    "#     datasets['train']['merged']['features'][2016]['nightlight']['default'],\n",
    "#     datasets['train']['merged']['features'][2016]['nightlight']['yeardiff']\n",
    "#]).float()\n",
    "#combinedFeatures = datasets['train']['merged']['features'][2016]['ndvi']['default'].merge(\n",
    "#     datasets['train']['merged']['features'][2016]['ndvi']['yeardiff'])\n",
    "#     datasets['train']['merged']['features'][2016]['nightlight']['default'],\n",
    "#     datasets['train']['merged']['features'][2016]['nightlight']['yeardiff']\n",
    "#])\n",
    "#def mergeBands (image, previous, bands=['ndvi_default']):\n",
    "#  return ee.Image(previous).addBands(image, [''])\n",
    "\n",
    "\n",
    "#combinedFeatures = dict()\n",
    "#labelMosaic = dict()\n",
    "merged_feature_and_gt = dict()\n",
    "for set_type in set_types:\n",
    "    if set_type not in merged_feature_and_gt:\n",
    "        merged_feature_and_gt[set_type] = dict()\n",
    "    for year in range(2015, 2018):\n",
    "    \n",
    "        labelMosaic = datasets['train']['merged']['labels'][2016].mosaic()\n",
    "        combinedFeatures = ee.ImageCollection([\n",
    "             datasets['train']['merged']['features'][2016]['ndvi']['default'].mosaic(),\n",
    "             datasets['train']['merged']['features'][2016]['ndvi']['yeardiff'].mosaic(),\n",
    "             datasets['train']['merged']['features'][2016]['nightlight']['default'].mosaic(),\n",
    "             datasets['train']['merged']['features'][2016]['nightlight']['yeardiff'].mosaic()\n",
    "        ])\n",
    "        merged_feature_and_gt[set_type][year] = combinedFeatures.merge(labelMosaic.select(['gt_lossyear'],['class'])).toBands()\n",
    "        old_band_names = merged_feature_and_gt[set_type][year].bandNames().getInfo()\n",
    "        new_band_names = ['ndvi_default', 'ndvi_yeardiff', 'nightlight_default', 'nightlight_yeardiff', 'class']\n",
    "        #rename bands\n",
    "        merged_feature_and_gt[set_type][year] = merged_feature_and_gt[set_type][year].select(old_band_names, new_band_names)\n",
    "#old_band_names = merged_feature_and_gt[2016].bandNames().getInfo()\n",
    "#new_band_names = ['ndvi_default', 'ndvi_yeardiff', 'nightlight_default', 'nightlight_yeardiff', 'class']\n",
    "band_names =merged_feature_and_gt['train'][2016].bandNames().getInfo() \n",
    "print('band names: {}'.format(band_names))\n",
    "\n",
    "\n",
    "\n",
    "mapid = merged_feature_and_gt['train'][2016].getMapId({'bands': ['ndvi_default'], 'min': 0, 'max': 1})\n",
    "#mapid = merged_feature_and_gt[2016].getMapId({'bands': ['class'], 'min': 0, 'max': 1})\n",
    "map = folium.Map(zoom_start=5)\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name='ground truth forest loss',\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BANDS = band_names\n",
    "#FEATURES = band_names\n",
    "LABEL = 'class'\n",
    "#FEATURES_AND_LABEL = FEATURES + [LABEL]\n",
    "FEATURES = BANDS + [LABEL]\n",
    "\n",
    "# Specify the size and shape of patches expected by the model.\n",
    "KERNEL_SIZE = 256\n",
    "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for f in FEATURES \n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "\n",
    "list = ee.List.repeat(1, KERNEL_SIZE)\n",
    "lists = ee.List.repeat(list, KERNEL_SIZE)\n",
    "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
    "\n",
    "year=2016\n",
    "train_featureStack = merged_feature_and_gt['train'][year]\n",
    "train_arrays = train_featureStack.neighborhoodToArray(kernel)\n",
    "\n",
    "val_featureStack = merged_feature_and_gt['val'][year]\n",
    "val_arrays = val_featureStack.neighborhoodToArray(kernel)\n",
    "\n",
    "eval_featureStack = merged_feature_and_gt['eval'][year]\n",
    "eval_arrays = eval_featureStack.neighborhoodToArray(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the feature collections to lists for iteration.\n",
    "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
    "evalPolysList = evalPolys.toList(evalPolys.size())\n",
    "valPolysList = valPolys.toList(valPolys.size())\n",
    "\n",
    "# Specify names locations for outputs in Cloud Storage. \n",
    "FOLDER = 'xingu_demo_v1'\n",
    "TRAINING_BASE = 'training_patches'\n",
    "VAL_BASE = 'val_patches'\n",
    "EVAL_BASE = 'eval_patches'\n",
    "BUCKET = 'xingu_data'\n",
    "\n",
    "# These numbers determined experimentally.\n",
    "#n = 200 # Number of shards in each polygon.\n",
    "#N = 2000 # Total sample size in each polygon.\n",
    "n = 20 # Number of shards in each polygon.\n",
    "N = 100 # Total sample size in each polygon.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training polygons: 11\n",
      "(train) starting cloud storage upload\n",
      "(train) starting cloud storage upload\n",
      "(train) starting cloud storage upload\n",
      "(train) starting cloud storage upload\n",
      "(train) starting cloud storage upload\n"
     ]
    }
   ],
   "source": [
    "# Export all the training data (in many pieces), with one task \n",
    "# per geometry.\n",
    "training_polys = trainingPolys.size().getInfo()\n",
    "print('training polygons: {}'.format(training_polys))\n",
    "for g in range(training_polys):\n",
    "  geomSample = ee.FeatureCollection([])\n",
    "  for i in range(n):\n",
    "    sample = train_arrays.sample(\n",
    "      region = ee.Feature(trainingPolysList.get(g)).geometry(), \n",
    "      scale = 30, \n",
    "      numPixels = N / n, # Size of the shard.\n",
    "      seed = i,\n",
    "      tileScale = 8\n",
    "    )\n",
    "    geomSample = geomSample.merge(sample)\n",
    "  \n",
    "  desc = TRAINING_BASE + '_g' + str(g)\n",
    "  task = ee.batch.Export.table.toCloudStorage(\n",
    "    collection = geomSample,\n",
    "    description = desc, \n",
    "    bucket = BUCKET, \n",
    "    fileNamePrefix = FOLDER + '/' + desc,\n",
    "    fileFormat = 'TFRecord',\n",
    "    selectors = FEATURES \n",
    "  )\n",
    "  print('(train) starting cloud storage upload')\n",
    "  task.start()\n",
    "    \n",
    "    \n",
    "for g in range(valPolys.size().getInfo()):\n",
    "  geomSample = ee.FeatureCollection([])\n",
    "  for i in range(n):\n",
    "    sample = val_arrays.sample(\n",
    "      region = ee.Feature(valPolysList.get(g)).geometry(), \n",
    "      scale = 30, \n",
    "      numPixels = N / n, # Size of the shard.\n",
    "      seed = i,\n",
    "      tileScale = 8\n",
    "    )\n",
    "    geomSample = geomSample.merge(sample)\n",
    "  \n",
    "  desc = VAL_BASE + '_g' + str(g)\n",
    "  task = ee.batch.Export.table.toCloudStorage(\n",
    "    collection = geomSample,\n",
    "    description = desc, \n",
    "    bucket = BUCKET, \n",
    "    fileNamePrefix = FOLDER + '/' + desc,\n",
    "    fileFormat = 'TFRecord',\n",
    "    selectors = FEATURES \n",
    "  )\n",
    "  print('(val) starting cloud storage upload')\n",
    "  task.start()\n",
    "    \n",
    "\n",
    "for g in range(evalPolys.size().getInfo()):\n",
    "  geomSample = ee.FeatureCollection([])\n",
    "  for i in range(n):\n",
    "    sample = eval_arrays.sample(\n",
    "      region = ee.Feature(evalPolysList.get(g)).geometry(), \n",
    "      scale = 30, \n",
    "      numPixels = N / n, # Size of the shard.\n",
    "      seed = i,\n",
    "      tileScale = 8\n",
    "    )\n",
    "    geomSample = geomSample.merge(sample)\n",
    "  \n",
    "  desc = EVAL_BASE + '_g' + str(g)\n",
    "  task = ee.batch.Export.table.toCloudStorage(\n",
    "    collection = geomSample,\n",
    "    description = desc, \n",
    "    bucket = BUCKET, \n",
    "    fileNamePrefix = FOLDER + '/' + desc,\n",
    "    fileFormat = 'TFRecord',\n",
    "    selectors = FEATURES \n",
    "  )\n",
    "  print('(eval) starting cloud storage upload')\n",
    "  task.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GS_AUTH_JSON = os.path.join(home, 'google_cloud/xingu_service.json')\n",
    "def parse_tfrecord(example_proto):\n",
    "  \"\"\"The parsing function.\n",
    "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "  Args:\n",
    "    example_proto: a serialized Example.\n",
    "  Returns: \n",
    "    A dictionary of tensors, keyed by feature name.\n",
    "  \"\"\"\n",
    "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "\n",
    "def to_tuple(inputs):\n",
    "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
    "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
    "  Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "  Returns: \n",
    "    A dtuple of (inputs, outputs).\n",
    "  \"\"\"\n",
    "  inputsList = [inputs.get(key) for key in FEATURES]\n",
    "  stacked = tf.stack(inputsList, axis=0)\n",
    "  # Convert from CHW to HWC\n",
    "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
    "\n",
    "\n",
    "def list_blobs_with_prefix(bucket_name, prefix):\n",
    "#    storage_client = storage.Client.from_service_account_json(\n",
    "#            GS_AUTH_JSON)\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(\n",
    "        bucket_name, prefix=prefix, delimiter=delimiter\n",
    "    )\n",
    "\n",
    "    return blobs\n",
    "\n",
    "def get_files_for_blobs(bucket_name, blobs):\n",
    "#    storage_client = storage.Client.from_service_account_json(\n",
    "#            GS_AUTH_JSON)\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    files= []\n",
    "    for blob in blobs:\n",
    "        blob_files = storage_client.list_blobs(\n",
    "            bucket_name, prefix=prefix, delimiter=delimiter\n",
    "        )\n",
    "\n",
    "    return blobs\n",
    "\n",
    "\n",
    "#def get_dataset(bucket, pattern):\n",
    "def get_dataset(pattern):\n",
    "    \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
    "    Get all the files matching the pattern, parse and convert to tuple.\n",
    "    Args:\n",
    "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
    "    Returns: \n",
    "    A tf.data.Dataset\n",
    "    \"\"\"\n",
    "  #glob = tf.gfile.Glob(pattern)\n",
    "    glob = tf.io.gfile.glob(pattern)\n",
    "    print('dataset matches: {}'.format(glob))\n",
    "\n",
    "#    from google.cloud import storage\n",
    "#    # Instantiates a client\n",
    "#    #storage_client = storage.Client()\n",
    "#    storage_client = storage.Client.from_service_account_json(\n",
    "#            os.path.join(home, 'google_cloud/xingu_service.json'))\n",
    "#    bucket = \n",
    "#    matched_files = list_blobs_with_prefix(bucket, pattern)trainingPolys.size().getInfo()\n",
    "#    print('matched files: {}'.format(matched_files))\n",
    "    #bucket_files = get_files_for_blobs(bucket, matched_files)\n",
    "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "    #print(dataset)\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "    dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "#home = str(Path.home())\n",
    "\n",
    "## Authorize Google Storage\n",
    "\n",
    "from google.cloud import storage\n",
    "# Instantiates a client\n",
    "storage_client = storage.Client()\n",
    "#storage_client = storage.Client.from_service_account_json(GS_AUTH_JSON)\n",
    "\n",
    "\n",
    "# The name for the new bucket\n",
    "\n",
    "# Make an authenticated API request\n",
    "buckets = storage_client.list_buckets()\n",
    "for bucket in buckets:\n",
    "    print(bucket.name)\n",
    "#bucket = storage_client.list_bucket(BUCKET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sizes of the training and evaluation datasets.\n",
    "TRAIN_SIZE = 16000\n",
    "EVAL_SIZE = 8000\n",
    "VAL_SIZE = 6000\n",
    "\n",
    "# Specify model training parameters.\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "BUFFER_SIZE = 3000\n",
    "OPTIMIZER = 'SGD'\n",
    "LOSS = 'MeanSquaredError'\n",
    "METRICS = ['RootMeanSquaredError']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    #glob = FOLDER + '/' + TRAINING_BASE + '*'\n",
    "    #glob = FOLDER + '/' + TRAINING_BASE \n",
    "    glob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TRAINING_BASE + '*'\n",
    "    #dataset = get_dataset(BUCKET, glob)\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "    return dataset\n",
    "\n",
    "training = get_training_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_training_sample = iter(training.take(1)).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect data\n",
    "\n",
    "print(first_training_sample[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_dataset():\n",
    "\t\"\"\"Get the preprocessed valuation dataset\n",
    "  Returns: \n",
    "    A tf.data.Dataset of evaluation data.\n",
    "  \"\"\"\n",
    "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + VAL_BASE + '*'\n",
    "\tdataset = get_dataset(glob)\n",
    "\tdataset = dataset.batch(1).repeat()\n",
    "\treturn dataset\n",
    "\n",
    "validation = get_val_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_validation_sample = iter(validation.take(1)).next()\n",
    "print(first_training_sample[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import metrics\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "\tencoder = layers.BatchNormalization()(encoder)\n",
    "\tencoder = layers.Activation('relu')(encoder)\n",
    "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "\tencoder = layers.BatchNormalization()(encoder)\n",
    "\tencoder = layers.Activation('relu')(encoder)\n",
    "\treturn encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "\tencoder = conv_block(input_tensor, num_filters)\n",
    "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "\treturn encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\treturn decoder\n",
    "\n",
    "def get_model():\n",
    "\tinputs = layers.Input(shape=[None, None, len(BANDS)]) # 256\n",
    "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
    "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
    "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
    "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
    "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
    "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
    "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
    "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
    "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
    "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
    "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
    "\toutputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)\n",
    "\n",
    "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=optimizers.get(OPTIMIZER), \n",
    "\t\tloss=losses.get(LOSS),\n",
    "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_model()\n",
    "\n",
    "m.fit(\n",
    "    x=training, \n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE))\n",
    "#    validation_data=validation,\n",
    "#    validation_steps=VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SF1_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
