{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Tile2Vec features for CDL classification\n",
    "In this notebook, we'll use a Tile2Vec model that has been pre-trained on the NAIP dataset to embed a small NAIP dataset and then train a classifier on the corresponding Cropland Data Layer (CDL) labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "#from time import time\n",
    "from torch.autograd import Variable\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.tilenet import make_tilenet\n",
    "from src.resnet import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Loading pre-trained model\n",
    "In this step, we will initialize a new TileNet model and then load the pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up model\n",
    "in_channels = 4\n",
    "z_dim = 512\n",
    "cuda = torch.cuda.is_available()\n",
    "#tilenet = make_tilenet(in_channels=in_channels, z_dim=z_dim)\n",
    "# Use old model for now\n",
    "tilenet = ResNet18()\n",
    "if cuda: tilenet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load parameters\n",
    "model_fn = '../models/naip_trained.ckpt'\n",
    "#checkpoint = torch.load(model_fn)\n",
    "checkpoint = torch.load(model_fn, map_location='cpu')\n",
    "tilenet.load_state_dict(checkpoint)\n",
    "tilenet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Embed NAIP tiles\n",
    "In this step, we'll use TileNet to embed the NAIP tiles provided in `tile2vec/data/tiles`. There are 1000 tiles in total, named `1tile.npy` through `1000tile.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "tile_dir = '../data/tiles'\n",
    "n_tiles = 1000\n",
    "y = np.load(os.path.join(tile_dir, 'y.npy'))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 50, 50])\n",
      "(50, 50, 4)\n",
      "(4, 50, 50)\n",
      "(1, 4, 50, 50)\n",
      "torch.Size([1, 4, 50, 50])\n",
      "torch.Size([1, 4, 50, 50])\n",
      "tensor([[[[0.7137, 0.7176, 0.7216,  ..., 0.6902, 0.6863, 0.6706],\n",
      "          [0.7137, 0.7098, 0.7137,  ..., 0.6980, 0.6902, 0.6863],\n",
      "          [0.7137, 0.7137, 0.7098,  ..., 0.6980, 0.6902, 0.6902],\n",
      "          ...,\n",
      "          [0.6980, 0.7020, 0.7020,  ..., 0.6902, 0.6902, 0.6902],\n",
      "          [0.6549, 0.6824, 0.6824,  ..., 0.6588, 0.6784, 0.6824],\n",
      "          [0.4471, 0.5176, 0.5176,  ..., 0.3608, 0.4784, 0.5294]],\n",
      "\n",
      "         [[0.6627, 0.6667, 0.6667,  ..., 0.6431, 0.6196, 0.6157],\n",
      "          [0.6627, 0.6588, 0.6588,  ..., 0.6353, 0.6314, 0.6275],\n",
      "          [0.6588, 0.6588, 0.6588,  ..., 0.6392, 0.6353, 0.6353],\n",
      "          ...,\n",
      "          [0.6431, 0.6471, 0.6471,  ..., 0.6353, 0.6431, 0.6471],\n",
      "          [0.5843, 0.6314, 0.6314,  ..., 0.5922, 0.6118, 0.6353],\n",
      "          [0.3843, 0.4784, 0.4784,  ..., 0.3294, 0.4275, 0.4902]],\n",
      "\n",
      "         [[0.5647, 0.5647, 0.5725,  ..., 0.5412, 0.5255, 0.5059],\n",
      "          [0.5765, 0.5725, 0.5765,  ..., 0.5608, 0.5373, 0.5333],\n",
      "          [0.5765, 0.5765, 0.5686,  ..., 0.5490, 0.5412, 0.5373],\n",
      "          ...,\n",
      "          [0.5647, 0.5765, 0.5765,  ..., 0.5686, 0.5725, 0.5765],\n",
      "          [0.5412, 0.5647, 0.5647,  ..., 0.5333, 0.5490, 0.5608],\n",
      "          [0.4235, 0.4588, 0.4588,  ..., 0.3922, 0.4431, 0.4667]],\n",
      "\n",
      "         [[0.7137, 0.7059, 0.7059,  ..., 0.6941, 0.6706, 0.6784],\n",
      "          [0.7020, 0.7020, 0.6980,  ..., 0.7020, 0.6941, 0.6980],\n",
      "          [0.7098, 0.7059, 0.6980,  ..., 0.6902, 0.6941, 0.6941],\n",
      "          ...,\n",
      "          [0.6824, 0.6941, 0.6941,  ..., 0.6784, 0.6784, 0.6863],\n",
      "          [0.6431, 0.6824, 0.6824,  ..., 0.6392, 0.6706, 0.6902],\n",
      "          [0.5647, 0.6510, 0.6510,  ..., 0.4902, 0.6078, 0.6863]]]])\n",
      "torch.Size([1, 4, 50, 50])\n",
      "tensor([[[[0.7137, 0.7176, 0.7216,  ..., 0.6902, 0.6863, 0.6706],\n",
      "          [0.7137, 0.7098, 0.7137,  ..., 0.6980, 0.6902, 0.6863],\n",
      "          [0.7137, 0.7137, 0.7098,  ..., 0.6980, 0.6902, 0.6902],\n",
      "          ...,\n",
      "          [0.6980, 0.7020, 0.7020,  ..., 0.6902, 0.6902, 0.6902],\n",
      "          [0.6549, 0.6824, 0.6824,  ..., 0.6588, 0.6784, 0.6824],\n",
      "          [0.4471, 0.5176, 0.5176,  ..., 0.3608, 0.4784, 0.5294]],\n",
      "\n",
      "         [[0.6627, 0.6667, 0.6667,  ..., 0.6431, 0.6196, 0.6157],\n",
      "          [0.6627, 0.6588, 0.6588,  ..., 0.6353, 0.6314, 0.6275],\n",
      "          [0.6588, 0.6588, 0.6588,  ..., 0.6392, 0.6353, 0.6353],\n",
      "          ...,\n",
      "          [0.6431, 0.6471, 0.6471,  ..., 0.6353, 0.6431, 0.6471],\n",
      "          [0.5843, 0.6314, 0.6314,  ..., 0.5922, 0.6118, 0.6353],\n",
      "          [0.3843, 0.4784, 0.4784,  ..., 0.3294, 0.4275, 0.4902]],\n",
      "\n",
      "         [[0.5647, 0.5647, 0.5725,  ..., 0.5412, 0.5255, 0.5059],\n",
      "          [0.5765, 0.5725, 0.5765,  ..., 0.5608, 0.5373, 0.5333],\n",
      "          [0.5765, 0.5765, 0.5686,  ..., 0.5490, 0.5412, 0.5373],\n",
      "          ...,\n",
      "          [0.5647, 0.5765, 0.5765,  ..., 0.5686, 0.5725, 0.5765],\n",
      "          [0.5412, 0.5647, 0.5647,  ..., 0.5333, 0.5490, 0.5608],\n",
      "          [0.4235, 0.4588, 0.4588,  ..., 0.3922, 0.4431, 0.4667]],\n",
      "\n",
      "         [[0.7137, 0.7059, 0.7059,  ..., 0.6941, 0.6706, 0.6784],\n",
      "          [0.7020, 0.7020, 0.6980,  ..., 0.7020, 0.6941, 0.6980],\n",
      "          [0.7098, 0.7059, 0.6980,  ..., 0.6902, 0.6941, 0.6941],\n",
      "          ...,\n",
      "          [0.6824, 0.6941, 0.6941,  ..., 0.6784, 0.6784, 0.6863],\n",
      "          [0.6431, 0.6824, 0.6824,  ..., 0.6392, 0.6706, 0.6902],\n",
      "          [0.5647, 0.6510, 0.6510,  ..., 0.4902, 0.6078, 0.6863]]]])\n",
      "torch.Size([1, 512])\n",
      "tensor([[5.3865e+00, 4.0491e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.5569e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1915e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4796e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0196e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4029e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4622e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 9.1904e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7467e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6643e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.6966e+00, 2.9856e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0847e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7301e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.8408e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.0082e-02, 1.5014e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3113e+00,\n",
      "         4.5873e+00, 8.1385e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3072e+01, 0.0000e+00, 0.0000e+00, 5.1545e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1842e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2080e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0067e+01, 0.0000e+00, 0.0000e+00, 1.7463e+00, 0.0000e+00, 1.3872e+01,\n",
      "         9.2952e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5345e-02,\n",
      "         0.0000e+00, 0.0000e+00, 1.6103e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.6795e+00, 0.0000e+00, 0.0000e+00, 6.5202e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5038e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3772e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5132e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2900e+01, 6.1396e-01,\n",
      "         2.9576e+00, 0.0000e+00, 1.6225e+00, 0.0000e+00, 0.0000e+00, 6.4852e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.2053e+00, 0.0000e+00, 0.0000e+00, 3.7698e+00,\n",
      "         5.5233e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0864e-02, 0.0000e+00,\n",
      "         0.0000e+00, 4.4736e-01, 0.0000e+00, 5.9321e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1860e-01, 0.0000e+00,\n",
      "         0.0000e+00, 5.7311e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9193e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.2822e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7434e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.7675e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0537e+01, 0.0000e+00, 3.1468e+00, 2.9427e-02, 0.0000e+00, 3.3949e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.8377e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2848e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.2351e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.5246e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7441e+01, 0.0000e+00,\n",
      "         0.0000e+00, 8.2838e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0818e+00, 1.6634e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.9317e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3101e+00, 0.0000e+00,\n",
      "         1.3692e+00, 0.0000e+00, 0.0000e+00, 8.4581e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0474e+01, 1.1416e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5275e-01, 0.0000e+00,\n",
      "         1.3232e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0427e+00, 5.4836e-01, 0.0000e+00, 1.7479e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7379e-02,\n",
      "         0.0000e+00, 1.4412e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.7916e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 9.2764e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.1228e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1905e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.5318e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8217e-01, 0.0000e+00,\n",
      "         3.5827e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0673e+00, 5.8242e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]], grad_fn=<ViewBackward>)\n",
      "(1, 512)\n",
      "[[5.38647223e+00 4.04911089e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.55694437e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.19152474e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.47957659e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.01959193e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.40294814e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.46216726e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.19037437e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.74666739e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.66432762e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.69663644e+00 2.98557609e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.08474773e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.73008275e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.84076080e+01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.00821877e-02 1.50140017e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.31128860e+00 4.58732176e+00 8.13851714e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.30715084e+01\n",
      "  0.00000000e+00 0.00000000e+00 5.15451312e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.18417871e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.20796185e+01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00667667e+01 0.00000000e+00 0.00000000e+00 1.74625993e+00\n",
      "  0.00000000e+00 1.38717031e+01 9.29518318e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.53449190e-02\n",
      "  0.00000000e+00 0.00000000e+00 1.61034393e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.67949283e+00 0.00000000e+00 0.00000000e+00 6.52024364e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.50379872e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.37720718e+01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.51319015e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.28995113e+01 6.13961041e-01\n",
      "  2.95762062e+00 0.00000000e+00 1.62252092e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.48515880e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 7.20526648e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.76976109e+00 5.52333951e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 7.08639771e-02 0.00000000e+00\n",
      "  0.00000000e+00 4.47362244e-01 0.00000000e+00 5.93214869e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.18598171e-01 0.00000000e+00\n",
      "  0.00000000e+00 5.73113060e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.91925931e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.28219719e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.74343580e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.76746702e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.05369835e+01 0.00000000e+00\n",
      "  3.14684701e+00 2.94269323e-02 0.00000000e+00 3.39494109e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.83768988e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.28483200e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.23508930e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.52462721e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.74413185e+01 0.00000000e+00 0.00000000e+00 8.28383982e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.08178186e+00 1.66340733e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.93166548e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.31009555e+00 0.00000000e+00\n",
      "  1.36916506e+00 0.00000000e+00 0.00000000e+00 8.45805645e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.04736938e+01 1.14156723e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.52752209e-01 0.00000000e+00 1.32316389e+01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.04268479e+00 5.48360884e-01\n",
      "  0.00000000e+00 1.74794078e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.73791808e-02\n",
      "  0.00000000e+00 1.44118756e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.79157364e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.27643299e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.12276316e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.19050026e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.53180873e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.82174653e-01 0.00000000e+00 3.58274269e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.06725454e+00\n",
      "  5.82420230e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 1000 tiles: 0.000s\n"
     ]
    }
   ],
   "source": [
    "# Embed tiles\n",
    "#t0 = time()\n",
    "X = np.zeros((n_tiles, z_dim))\n",
    "for idx in range(n_tiles):\n",
    "    if idx == 0:\n",
    "        print(tile.shape) \n",
    "    tile = np.load(os.path.join(tile_dir, '{}tile.npy'.format(idx+1)))\n",
    "    # Get first 4 NAIP channels (5th is CDL mask)\n",
    "    tile = tile[:,:,:4]\n",
    "    if idx == 0:\n",
    "        print(tile.shape)\n",
    "    # Rearrange to PyTorch order\n",
    "    tile = np.moveaxis(tile, -1, 0)\n",
    "    if idx == 0:\n",
    "        print(tile.shape)\n",
    "    tile = np.expand_dims(tile, axis=0)\n",
    "    if idx == 0:\n",
    "        print(tile.shape)\n",
    "        #print(tile)\n",
    "    # Scale to [0, 1]\n",
    "    tile = tile / 255\n",
    "    # Embed tile\n",
    "    tile = torch.from_numpy(tile).float()\n",
    "    if idx == 0:\n",
    "        print(tile.shape)\n",
    "        #print(tile)\n",
    "    tile = Variable(tile)\n",
    "    if idx == 0:\n",
    "        print(tile.shape)\n",
    "        print(tile)\n",
    "    if cuda: tile = tile.cuda()\n",
    "    if idx == 0:\n",
    "        print(tile.shape)\n",
    "        print(tile)\n",
    "    z = tilenet.encode(tile)\n",
    "    if idx == 0:\n",
    "        print(z.shape)\n",
    "        print(z)\n",
    "    if cuda: z = z.cpu()\n",
    "    z = z.data.numpy()\n",
    "    if idx == 0:\n",
    "        print(z.shape)\n",
    "        print(z)\n",
    "    X[idx,:] = z\n",
    "#t1 = time()\n",
    "print('Embedded {} tiles: {:0.3f}s'.format(n_tiles, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Train random forest classifier\n",
    "In this step, we'll split the dataset into train and test sets and train a random forest classifier to predict CDL classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0, 2.0, 21.0, 152.0, 24.0, 28.0, 36.0, 176.0, 49.0, 54.0, 61.0, 69.0, 71.0, 72.0, 75.0, 76.0, 205.0, 204.0, 208.0, 212.0, 217.0, 225.0, 236.0, 111.0, 121.0, 122.0, 123.0, 124.0}\n"
     ]
    }
   ],
   "source": [
    "# Check CDL classes\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the CDL classes are not numbered in consecutive order, we'll start by reindexing the classes from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27}\n"
     ]
    }
   ],
   "source": [
    "# Reindex CDL classes\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can randomly split the data and train a random forest classifier many times to get an estimate of the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6876\n",
      "Standard deviation: 0.0299\n"
     ]
    }
   ],
   "source": [
    "n_trials = 100\n",
    "accs = np.zeros((n_trials,))\n",
    "for i in range(n_trials):\n",
    "    # Splitting data and training RF classifer\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2)\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    accs[i] = rf.score(X_te, y_te)\n",
    "print('Mean accuracy: {:0.4f}'.format(accs.mean()))\n",
    "print('Standard deviation: {:0.4f}'.format(accs.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
