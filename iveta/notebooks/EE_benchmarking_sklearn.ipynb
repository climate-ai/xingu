{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentinel-2 image patches of 7x7 pixels for 10 bands including labels \\\n",
    "\\\n",
    "index files: https://drive.google.com/open?id=14o0eu_UN8RZW68HGR0xHA3es9p_gmuw1 \\\n",
    "training data: https://drive.google.com/open?id=17njNHAyoexj8WmThKfdQzVr18bevGVZ3 \\\n",
    "validation data: https://drive.google.com/open?id=1TtfVv4JomTJW1CKTCX2o4QgUnkoD9iu1 \\\n",
    "testing data: https://drive.google.com/open?id=1RwkC-KitWSeCbLpMhlq7OAlWJgtYx9PS \\\n",
    "\\\n",
    "data format: TFRecord files with featureDict format as defined below, each file containing ca. 20 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "import png\n",
    "import matplotlib.pyplot as plt\n",
    "#import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()\n",
    "try:\n",
    "    tf.enable_eager_execution()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and parse TFRecord data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "## Define files' paths for TFRecord data\n",
    "\n",
    "filenames_train = []\n",
    "filenames_validate = []\n",
    "filenames_test = []\n",
    "\n",
    "no_files_train = 3000\n",
    "no_files_validate = 1000\n",
    "no_files_test = 1000\n",
    "\n",
    "no_records_train = 62434\n",
    "no_records_validate = 21097\n",
    "no_records_test = 21189\n",
    "\n",
    "for i in range(no_files_train):\n",
    "    filenames_train.append(\"../data/EE_data/EE_data_training/train_patches_\"+\"{0:04}\".format(i)+\".tfrecord\") \n",
    "\n",
    "for i in range(no_files_validate):\n",
    "    filenames_validate.append(\"../data/EE_data/EE_data_validation/validate_patches_\"+\"{0:04}\".format(i)+\".tfrecord\")\n",
    "    \n",
    "for i in range(no_files_validate):\n",
    "    filenames_test.append(\"../data/EE_data/EE_data_testing/test_patches_\"+\"{0:04}\".format(i)+\".tfrecord\") \n",
    "    \n",
    "print(len(filenames_train))\n",
    "print(len(filenames_validate))\n",
    "print(len(filenames_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define dictionary with features in TFRecord data\n",
    "\n",
    "no_pixels = 7*7\n",
    "no_channels = 10\n",
    "\n",
    "bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
    "label_names = ['vegetation_elementstree_element_cover_label', \\\n",
    "                'vegetation_elementsshrub_element_cover_label', \\\n",
    "                'vegetation_elementspalm_element_cover_label', \\\n",
    "                'vegetation_elementsbamboo_element_cover_label', \\\n",
    "                'vegetation_elementscrop_element_cover_label', \\\n",
    "                'infrastructure_elementshouse_element_cover_label', \\\n",
    "                'infrastructure_elementsother_buildings_element_cover_label', \\\n",
    "                'infrastructure_elementspaved_road_element_cover_label', \\\n",
    "                'infrastructure_elementsunpaved_road_element_cover_label', \\\n",
    "                'water_bodieslake_water_cover_label', \\\n",
    "                'water_bodiesriver_water_cover_label', \\\n",
    "                'total_water_bodies_cover_label']\n",
    "\n",
    "featureDict = {}\n",
    "featureDict['public_id'] = tf.io.FixedLenFeature(shape=[1], dtype=tf.string)\n",
    "for band in bands:\n",
    "    featureDict[band] = tf.io.FixedLenFeature(shape=[7,7], dtype=tf.float32,\\\n",
    "                            default_value=tf.zeros([7,7], dtype=tf.float32))\n",
    "for label_name in label_names:\n",
    "    featureDict[label_name] = tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "#print(featureDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export tensorflow dataset into numpy arrays\n",
    "\n",
    "def _parse_for_export_(serialized_example):\n",
    "    example = tf.parse_single_example(serialized_example, featureDict)\n",
    "    d = {}\n",
    "    for band in bands:\n",
    "        d[band] = example[band]\n",
    "        d[band] = tf.reshape(example[band], (49,))\n",
    "    for label in label_names:\n",
    "        d[label] = example[label]\n",
    "        d[label] = tf.cast(example[label], tf.int32)\n",
    "    d['public_id'] = tf.cast(example['public_id'], tf.string)\n",
    "    return d\n",
    "\n",
    "def input_fn_export(filenames = filenames_train):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_for_export_(x))\n",
    "    return tfrecord_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 490)\n",
      "(1, 12)\n",
      "(1, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-06fbef5c2ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     new_row = np.concatenate([np.asarray(numpy_dataset_train[i][band],\\\n\u001b[1;32m     19\u001b[0m                               dtype=np.float32).reshape((1,-1)) for band in bands], axis = 1)\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     new_row = np.concatenate([np.asarray(numpy_dataset_train[i][label],\\\n\u001b[1;32m     22\u001b[0m                               dtype=np.int32).reshape((1,-1)) for label in label_names], axis = 1)\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Export training data to numpy arrays\n",
    "dataset_train_for_export = input_fn_export(filenames_train)\n",
    "numpy_dataset_train = list(dataset_train_for_export.as_numpy_iterator())\n",
    "\n",
    "list_of_features_0 = [np.asarray(numpy_dataset_train[0][band], dtype=np.float32).reshape((1,-1)) for band in bands]\n",
    "x_train = np.concatenate(list_of_features_0,axis = 1)\n",
    "print(x_train.shape)\n",
    "\n",
    "list_of_labels_0 = [np.asarray(numpy_dataset_train[0][label], dtype=np.int32).reshape((1,-1)) for label in label_names]\n",
    "y_train = np.concatenate(list_of_labels_0,axis = 1)\n",
    "print(y_train.shape)\n",
    "\n",
    "id_train = np.asarray(numpy_dataset_train[0]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "print(id_train.shape)\n",
    "\n",
    "for i in range(1, no_records_train):\n",
    "#for i in range(1, 30):\n",
    "    new_row = np.concatenate([np.asarray(numpy_dataset_train[i][band],\\\n",
    "                              dtype=np.float32).reshape((1,-1)) for band in bands], axis = 1)\n",
    "    x_train = np.concatenate((x_train, new_row), axis = 0)\n",
    "    new_row = np.concatenate([np.asarray(numpy_dataset_train[i][label],\\\n",
    "                              dtype=np.int32).reshape((1,-1)) for label in label_names], axis = 1)\n",
    "    y_train = np.concatenate((y_train, new_row), axis = 0)\n",
    "    \n",
    "    new_row = np.asarray(numpy_dataset_train[i]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "    id_train = np.concatenate((id_train, new_row), axis = 0)\n",
    "    \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(id_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export validation data to numpy arrays\n",
    "dataset_validate_for_export = input_fn_export(filenames_validate)\n",
    "numpy_dataset_validate = list(dataset_validate_for_export.as_numpy_iterator())\n",
    "\n",
    "list_of_features_0 = [np.asarray(numpy_dataset_validate[0][band], dtype=np.float32).reshape((1,-1)) for band in bands]\n",
    "x_validate = np.concatenate(list_of_features_0,axis = 1)\n",
    "print(x_validate.shape)\n",
    "\n",
    "list_of_labels_0 = [np.asarray(numpy_dataset_validate[0][label], dtype=np.int32).reshape((1,-1)) for label in label_names]\n",
    "y_validate = np.concatenate(list_of_labels_0,axis = 1)\n",
    "print(y_validate.shape)\n",
    "\n",
    "id_validate = np.asarray(numpy_dataset_validate[0]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "print(id_validate.shape)\n",
    "\n",
    "for i in range(1, no_records_validate):\n",
    "#for i in range(1, 30):\n",
    "    new_row = np.concatenate([np.asarray(numpy_dataset_validate[i][band],\\\n",
    "                              dtype=np.float32).reshape((1,-1)) for band in bands], axis = 1)\n",
    "    x_validate = np.concatenate((x_validate, new_row), axis = 0)\n",
    "    \n",
    "    new_row = np.concatenate([np.asarray(numpy_dataset_validate[i][label],\\\n",
    "                              dtype=np.int32).reshape((1,-1)) for label in label_names], axis = 1)\n",
    "    y_validate = np.concatenate((y_validate, new_row), axis = 0)\n",
    "    \n",
    "    new_row = np.asarray(numpy_dataset_validate[i]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "    id_validate = np.concatenate((id_validate, new_row), axis = 0)\n",
    "    \n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(id_validate.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export test data to numpy arrays\n",
    "dataset_test_for_export = input_fn_export(filenames_test)\n",
    "numpy_dataset_test = list(dataset_test_for_export.as_numpy_iterator())\n",
    "\n",
    "list_of_features_0 = [np.asarray(numpy_dataset_test[0][band], dtype=np.float32).reshape((1,-1)) for band in bands]\n",
    "x_test = np.concatenate(list_of_features_0,axis = 1)\n",
    "print(x_test.shape)\n",
    "\n",
    "list_of_labels_0 = [np.asarray(numpy_dataset_test[0][label], dtype=np.int32).reshape((1,-1)) for label in label_names]\n",
    "y_test = np.concatenate(list_of_labels_0,axis = 1)\n",
    "print(y_test.shape)\n",
    "\n",
    "id_test = np.asarray(numpy_dataset_test[0]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "print(id_test.shape)\n",
    "\n",
    "for i in range(1, no_records_test):\n",
    "#for i in range(1, 30):\n",
    "    new_row = np.concatenate([np.asarray(numpy_dataset_test[i][band],\\\n",
    "                              dtype=np.float32).reshape((1,-1)) for band in bands], axis = 1)\n",
    "    x_test = np.concatenate((x_test, new_row), axis = 0)\n",
    "    \n",
    "    new_row = np.concatenate([np.asarray(numpy_dataset_test[i][label],\\\n",
    "                              dtype=np.int32).reshape((1,-1)) for label in label_names], axis = 1)\n",
    "    y_test = np.concatenate((y_test, new_row), axis = 0)\n",
    "    \n",
    "    new_row = np.asarray(numpy_dataset_test[i]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "    id_test = np.concatenate((id_test, new_row), axis = 0)\n",
    "    \n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(id_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save data as numpy arrays on disk\n",
    "\n",
    "np.save('../data/EE_data/x_train_2.npy', x_train)\n",
    "np.save('../data/EE_data/y_train_\".npy', y_train)\n",
    "np.save('../data/EE_data/id_train_2.npy', id_train)\n",
    "\n",
    "np.save('../data/EE_data/x_validate_2.npy', x_validate)\n",
    "np.save('../data/EE_data/y_validate_2.npy', y_validate)\n",
    "np.save('../data/EE_data/id_validate_2.npy', id_validate)\n",
    "\n",
    "np.save('../data/EE_data/x_test_2.npy', x_test)\n",
    "np.save('../data/EE_data/y_test_2.npy', y_test)\n",
    "np.save('../data/EE_data/id_test_2.npy', id_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load numpy Sentinel data with labels\n",
    "x_train = np.load('../data/EE_data/x_train.npy')\n",
    "y_train = np.load('../data/EE_data/y_train.npy')\n",
    "id_train = np.load('../data/EE_data/id_train.npy')\n",
    "\n",
    "x_validate = np.load('../data/EE_data/x_validate.npy')\n",
    "y_validate = np.load('../data/EE_data/y_validate.npy')\n",
    "id_validate = np.load('../data/EE_data/id_validate.npy')\n",
    "\n",
    "x_test = np.load('../data/EE_data/x_test.npy')\n",
    "y_test = np.load('../data/EE_data/y_test.npy')\n",
    "id_test = np.load('../data/EE_data/id_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import ElasticNet\n",
    "#from sklearn.linear_model import ElasticNetCV\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### benchmarking - full 10 band original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples:  100\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.6755936863061098\n",
      "Confusion matrix: \n",
      " [[6981  101   16  126    1   20   41  232    1 1217]\n",
      " [ 499    6    2   11    0    4   11   18    0  202]\n",
      " [ 319    3    1    7    0    4    5    8    0  141]\n",
      " [ 179    2    0    2    0    2    7    7    0  124]\n",
      " [ 187    2    0    6    0    2    4    9    0  152]\n",
      " [ 121    4    0    4    0    1    2    3    0  143]\n",
      " [ 121    5    0    4    0    0    1    4    0  145]\n",
      " [ 109    3    0    7    0    0    4    5    0  188]\n",
      " [ 214    8    0    6    1    2    7    7    0  362]\n",
      " [1372  115    3  134    0    5   43   25    1 7256]]\n",
      "# of training samples:  200\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7153623737972223\n",
      "Confusion matrix: \n",
      " [[7297   27    8    0    0   12   12    7    0 1373]\n",
      " [ 511    2    1    0    0    2    2    1    0  234]\n",
      " [ 332    3    0    0    0    3    2    0    0  148]\n",
      " [ 190    1    0    0    0    1    3    0    0  128]\n",
      " [ 194    0    0    0    0    1    1    1    0  165]\n",
      " [ 124    1    0    0    0    0    1    0    0  152]\n",
      " [ 126    1    0    0    0    1    0    0    0  152]\n",
      " [ 120    0    0    0    0    0    0    0    0  196]\n",
      " [ 209    1    0    0    0    1    3    0    0  393]\n",
      " [1136    6    0    0    0    8    5    1    5 7793]]\n",
      "# of training samples:  500\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7125657676446888\n",
      "Confusion matrix: \n",
      " [[7381   45    1   22    0    1    2    0    2 1282]\n",
      " [ 544    1    0    0    0    0    0    0    0  208]\n",
      " [ 341    2    0    0    0    0    1    0    0  144]\n",
      " [ 202    0    0    0    0    0    1    0    0  120]\n",
      " [ 207    1    0    1    1    0    0    0    1  151]\n",
      " [ 132    0    0    0    0    0    0    1    0  145]\n",
      " [ 129    1    0    1    0    0    0    0    0  149]\n",
      " [ 123    0    0    2    0    0    0    0    0  191]\n",
      " [ 218    1    0    4    1    0    0    0    0  383]\n",
      " [1213    7    1   48    1    1    3   10   20 7650]]\n",
      "# of training samples:  1000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7184433805754372\n",
      "Confusion matrix: \n",
      " [[7522    1    1    2    0    0    0    0    3 1207]\n",
      " [ 555    0    0    3    0    0    0    0    0  195]\n",
      " [ 365    0    0    1    0    0    0    0    1  121]\n",
      " [ 206    0    0    0    0    0    0    0    0  117]\n",
      " [ 215    0    0    0    0    0    0    0    0  147]\n",
      " [ 135    0    0    0    0    0    0    0    1  142]\n",
      " [ 136    0    0    0    0    0    0    0    0  144]\n",
      " [ 121    1    0    0    0    0    0    0    0  194]\n",
      " [ 237    0    0    1    0    0    0    0    0  369]\n",
      " [1313    1    1    3    0    0    0    0    1 7635]]\n",
      "# of training samples:  2000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7270227994501588\n",
      "Confusion matrix: \n",
      " [[7547    1    0    0    0    0    0    0    1 1187]\n",
      " [ 545    1    0    0    0    0    0    0    0  207]\n",
      " [ 357    0    0    0    0    0    0    0    0  131]\n",
      " [ 203    0    0    0    0    0    0    0    0  120]\n",
      " [ 216    1    0    0    0    0    0    0    0  145]\n",
      " [ 136    0    0    0    0    0    0    0    0  142]\n",
      " [ 134    0    0    0    0    0    0    0    0  146]\n",
      " [ 119    0    0    0    0    0    0    0    0  197]\n",
      " [ 235    0    0    0    0    0    0    0    1  371]\n",
      " [1160    0    1    0    2    0    0    0    2 7789]]\n",
      "# of training samples:  5000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7341802151964735\n",
      "Confusion matrix: \n",
      " [[7553    1    0    0    0    0    0    0    1 1181]\n",
      " [ 549    0    0    0    0    0    0    0    0  204]\n",
      " [ 355    0    0    0    0    0    0    0    0  133]\n",
      " [ 214    0    0    0    0    0    0    0    0  109]\n",
      " [ 202    0    0    0    1    0    0    0    0  159]\n",
      " [ 132    0    0    0    0    0    0    0    0  146]\n",
      " [ 132    0    0    0    0    0    0    0    0  148]\n",
      " [ 112    0    0    0    0    0    0    0    0  204]\n",
      " [ 219    0    0    0    0    0    0    0    0  388]\n",
      " [1015    2    0    0    0    2    0    0    0 7935]]\n",
      "# of training samples:  10000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7346068161349955\n",
      "Confusion matrix: \n",
      " [[7582    0    0    0    0    0    1    0    0 1153]\n",
      " [ 549    0    0    0    0    0    0    0    0  204]\n",
      " [ 359    0    0    0    1    0    0    0    0  128]\n",
      " [ 214    0    0    0    0    0    0    0    0  109]\n",
      " [ 209    0    0    0    0    0    0    0    0  153]\n",
      " [ 135    0    0    0    0    0    0    0    0  143]\n",
      " [ 132    0    0    0    0    0    0    0    0  148]\n",
      " [ 115    0    0    0    0    0    0    0    0  201]\n",
      " [ 213    0    0    0    0    0    0    0    0  394]\n",
      " [1036    0    0    0    0    2    0    0    0 7916]]\n"
     ]
    }
   ],
   "source": [
    "## Benchmark classification of Sentinel-2 data using sklearn RandomForestClassifier\n",
    "\n",
    "# Normalize data\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(x_train)\n",
    "#x_train_tr = scaler.transform(x_train)\n",
    "#x_validate_tr = scaler.transform(x_validate)\n",
    "\n",
    "# Make scorer\n",
    "#acc_score=make_scorer(accuracy_score)\n",
    "\n",
    "# Train/fit the model and predict results for different numbers of samples\n",
    "no_samples_array = [100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "#no_samples_array = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 5000, 10000, 20000, 60000]\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=1000, bootstrap=False, class_weight='balanced')\n",
    "\n",
    "for no_samples in no_samples_array:\n",
    "    print(\"# of training samples: \", no_samples)\n",
    "    \n",
    "    #val_no_samples = min(int(no_samples/3), no_records_validate)\n",
    "    val_no_samples = no_records_validate\n",
    "    print(\"# of validation samples: \", val_no_samples)\n",
    "    \n",
    "    clf.fit(x_train[:no_samples, :],y_train[:no_samples,0]) #first column of y: tree cover label\n",
    "    y_pred = clf.predict(x_validate[:val_no_samples,:])\n",
    "\n",
    "    # evaluate accuracy\n",
    "    acc = clf.score(x_validate[:val_no_samples,:], y_validate[:val_no_samples,0])\n",
    "    accuracies.append(acc)\n",
    "    print(\"Accuracy score: \", acc)\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_validate[:val_no_samples,0], y_pred)\n",
    "    confusion_matrices.append(conf_mat)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 200, 500, 1000, 2000, 5000, 10000]\n",
      "[0.6755936863061098, 0.7153623737972223, 0.7125657676446888, 0.7184433805754372, 0.7270227994501588, 0.7341802151964735, 0.7346068161349955]\n"
     ]
    }
   ],
   "source": [
    "print(no_samples_array)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### benchmarking - full 10 band original reordered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benchmark classification of Sentinel-2 data using sklearn RandomForestClassifier\n",
    "## with preprocessing of data\n",
    "\n",
    "no_pixels = 7*7\n",
    "no_channels = 10\n",
    "\n",
    "# Preprocess data by reordering pixels in all 10 channels to the order of green+blue channel pixels\n",
    "# by value, i.e. \"greenest+bluest\" pixel first, \"least green+blue\" last\n",
    "\n",
    "# Training data\n",
    "x_train_r = np.zeros(x_train.shape)\n",
    "for i in range(x_train.shape[0]):\n",
    "#for i in range(30):\n",
    "    # Find order of indices by of the green channel by value\n",
    "    g = x_train[i, bands.index('B3')*no_pixels : (bands.index('B3')+1)*(no_pixels)] #green channel = B3\n",
    "    b = x_train[i, bands.index('B2')*no_pixels : (bands.index('B2')+1)*(no_pixels)] #blue channel = B2\n",
    "    gb = np.add(g,b)\n",
    "    sorted_indices = np.argsort(gb)\n",
    "    for j in range(no_channels):\n",
    "        for k in range(no_pixels):\n",
    "            x_train_r[i,(j*no_pixels)+k] = x_train[i,(j*no_pixels)+sorted_indices[k]]\n",
    "            \n",
    "# Validation data\n",
    "x_validate_r = np.zeros(x_validate.shape)\n",
    "for i in range(x_validate.shape[0]):\n",
    "#for i in range(30):\n",
    "    # Find order of indices by of the green channel by value\n",
    "    g = x_validate[i, bands.index('B3')*no_pixels : (bands.index('B3')+1)*(no_pixels)] #green channel = B3\n",
    "    b = x_train[i, bands.index('B2')*no_pixels : (bands.index('B2')+1)*(no_pixels)] #blue channel = B2\n",
    "    gb = np.add(g,b)\n",
    "    sorted_indices = np.argsort(gb)\n",
    "    for j in range(no_channels):\n",
    "        for k in range(no_pixels):\n",
    "            x_validate_r[i,j*no_pixels + k] = x_validate[i,j*no_pixels + sorted_indices[k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID : ['GLU0340923']\n",
      "Tree cover label : 0\n",
      "All cover labels : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display one train image after reordering\n",
    "image_id = 118\n",
    "print(\"ID :\", id_train[image_id])\n",
    "print(\"Tree cover label :\", y_train[image_id,0])\n",
    "print(\"All cover labels :\", y_train[image_id,:])\n",
    "\n",
    "rgbArray_r = np.zeros((7,7,3))\n",
    "rgbArray_r[..., 0] = x_train_r[image_id, bands.index('B4')*no_pixels:(bands.index('B4') + 1)*no_pixels].reshape((7,7))\n",
    "rgbArray_r[..., 1] = x_train_r[image_id, bands.index('B3')*no_pixels:(bands.index('B3') + 1)*no_pixels].reshape((7,7))\n",
    "rgbArray_r[..., 2] = x_train_r[image_id, bands.index('B2')*no_pixels:(bands.index('B2') + 1)*no_pixels].reshape((7,7))\n",
    "rgbArray_r[rgbArray_r > 0.3] = 0.3\n",
    "rgbArray_r = rgbArray_r / 0.3\n",
    "\n",
    "rgbArray = np.zeros((7,7,3))\n",
    "rgbArray[..., 0] = x_train[image_id, bands.index('B4')*no_pixels:(bands.index('B4') + 1)*no_pixels].reshape((7,7))\n",
    "rgbArray[..., 1] = x_train[image_id, bands.index('B3')*no_pixels:(bands.index('B3') + 1)*no_pixels].reshape((7,7))\n",
    "rgbArray[..., 2] = x_train[image_id, bands.index('B2')*no_pixels:(bands.index('B2') + 1)*no_pixels].reshape((7,7))\n",
    "rgbArray[rgbArray > 0.3] = 0.3\n",
    "rgbArray = rgbArray / 0.3\n",
    "#print(rgbArray)\n",
    "\n",
    "images = [rgbArray, rgbArray_r]\n",
    "\n",
    "for ima in images:\n",
    "    plt.figure()\n",
    "    plt.imshow(ima, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples:  100\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.6774422903730388\n",
      "Confusion matrix: \n",
      " [[6972   35    7  147    6    6   87  174   10 1292]\n",
      " [ 482    6    1   15    3    0   30   18    1  197]\n",
      " [ 301    6    0   10    0    0   13   11    2  145]\n",
      " [ 173    1    0    2    0    0   11    7    0  129]\n",
      " [ 170    1    0   10    1    1    8   13    0  158]\n",
      " [ 111    4    0    6    0    2    9    4    1  141]\n",
      " [ 115    3    0    7    0    2    4    4    1  144]\n",
      " [ 105    0    0    7    0    1   11    4    0  188]\n",
      " [ 205    6    0    7    0    1   11    6    1  370]\n",
      " [1270   61    0  169    0    2  103   21   28 7300]]\n",
      "# of training samples:  200\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7132767692088923\n",
      "Confusion matrix: \n",
      " [[7268    4    2    1    0    8   25    0    2 1426]\n",
      " [ 512    2    0    0    0    1    3    0    0  235]\n",
      " [ 330    0    0    0    0    1    3    0    0  154]\n",
      " [ 191    0    0    0    0    0    2    0    0  130]\n",
      " [ 193    0    1    0    0    2    1    0    0  165]\n",
      " [ 118    0    0    0    0    0    4    0    0  156]\n",
      " [ 119    0    1    0    0    1    0    0    0  159]\n",
      " [ 116    0    0    0    0    1    0    0    0  199]\n",
      " [ 202    0    0    0    0    1    4    0    0  400]\n",
      " [1159    0    0    0    0    2   13    0    2 7778]]\n",
      "# of training samples:  500\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7089633597193914\n",
      "Confusion matrix: \n",
      " [[7359   69    3   38    4   11    1    0    0 1251]\n",
      " [ 533    5    2    4    0    1    0    0    0  208]\n",
      " [ 352    5    0    1    0    2    0    0    0  128]\n",
      " [ 198    1    0    1    0    2    0    0    0  121]\n",
      " [ 202    1    1    1    0    1    0    0    0  156]\n",
      " [ 121    2    0    2    0    1    0    1    0  151]\n",
      " [ 135    1    1    5    0    0    0    0    0  138]\n",
      " [ 123    1    0    1    0    0    0    0    1  190]\n",
      " [ 218    3    0    4    0    1    1    0    0  380]\n",
      " [1244   15    1   76    0    4    0   10   13 7591]]\n",
      "# of training samples:  1000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7188699815139593\n",
      "Confusion matrix: \n",
      " [[7505    1    0    2    1    4    2    0    1 1220]\n",
      " [ 553    1    0    0    0    0    0    0    0  199]\n",
      " [ 366    0    0    0    0    0    0    0    1  121]\n",
      " [ 212    0    0    1    0    0    1    0    0  109]\n",
      " [ 207    0    0    0    0    0    0    0    0  155]\n",
      " [ 133    1    0    0    0    0    0    0    0  144]\n",
      " [ 136    0    0    0    0    0    0    0    0  144]\n",
      " [ 127    0    0    0    0    0    0    0    0  189]\n",
      " [ 236    0    0    1    0    0    0    0    0  370]\n",
      " [1284    0    1    3    0    0    2    0    5 7659]]\n",
      "# of training samples:  2000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7270227994501588\n",
      "Confusion matrix: \n",
      " [[7571    5    0    0    1    0    3    0    2 1154]\n",
      " [ 545    0    2    1    0    0    0    0    0  205]\n",
      " [ 363    0    1    0    1    0    0    0    0  123]\n",
      " [ 210    1    0    0    0    0    0    0    0  112]\n",
      " [ 216    0    0    1    0    0    0    0    0  145]\n",
      " [ 132    0    0    0    0    0    0    0    0  146]\n",
      " [ 141    0    0    0    0    0    0    0    0  139]\n",
      " [ 130    0    0    0    0    0    0    0    0  186]\n",
      " [ 227    0    0    0    0    0    0    0    1  379]\n",
      " [1180    2    3    0    1    0    1    0    2 7765]]\n",
      "# of training samples:  5000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7345594160307153\n",
      "Confusion matrix: \n",
      " [[7576    1    1    1    0    0    0    0    1 1156]\n",
      " [ 545    0    0    0    0    0    0    0    0  208]\n",
      " [ 354    0    0    0    0    0    0    0    0  134]\n",
      " [ 211    0    1    0    0    0    0    0    0  111]\n",
      " [ 209    0    0    0    0    1    0    0    0  152]\n",
      " [ 128    0    0    0    1    0    1    0    0  148]\n",
      " [ 133    0    0    0    0    0    0    0    0  147]\n",
      " [ 122    0    0    0    0    0    0    0    0  194]\n",
      " [ 217    0    0    0    0    0    0    0    0  390]\n",
      " [1030    0    0    0    0    3    0    0    0 7921]]\n",
      "# of training samples:  10000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.735744418637721\n",
      "Confusion matrix: \n",
      " [[7588    0    0    0    0    0    1    0    0 1147]\n",
      " [ 556    0    0    0    0    0    0    0    0  197]\n",
      " [ 354    0    0    0    1    0    0    0    0  133]\n",
      " [ 214    0    0    0    0    0    0    0    0  109]\n",
      " [ 213    0    0    0    0    0    0    0    0  149]\n",
      " [ 134    0    0    0    1    0    1    0    0  142]\n",
      " [ 133    0    0    0    0    0    0    0    0  147]\n",
      " [ 118    0    0    0    0    0    0    1    0  197]\n",
      " [ 217    0    0    0    0    0    0    0    0  390]\n",
      " [1019    0    0    0    1    1    0    0    0 7933]]\n"
     ]
    }
   ],
   "source": [
    "## Classify for benchmarking values\n",
    "\n",
    "no_samples_array = [100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "#no_samples_array = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 5000, 10000, 20000, 60000]\n",
    "accuracies_r = []\n",
    "confusion_matrices_r = []\n",
    "\n",
    "clf_r = RandomForestClassifier(random_state=0, n_estimators=100, bootstrap=False, class_weight='balanced')\n",
    "\n",
    "for no_samples in no_samples_array:\n",
    "    print(\"# of training samples: \", no_samples)\n",
    "    \n",
    "    #val_no_samples = min(int(no_samples/3), no_records_validate)\n",
    "    val_no_samples = no_records_validate\n",
    "    print(\"# of validation samples: \", val_no_samples)\n",
    "    \n",
    "    clf_r.fit(x_train_r[:no_samples, :],y_train[:no_samples,0]) #first column of y: tree cover label\n",
    "    y_pred = clf_r.predict(x_validate_r[:val_no_samples,:])\n",
    "\n",
    "    # evaluate accuracy\n",
    "    acc_r = clf_r.score(x_validate_r[:val_no_samples,:], y_validate[:val_no_samples,0])\n",
    "    accuracies_r.append(acc_r)\n",
    "    print(\"Accuracy score: \", acc_r)\n",
    "    \n",
    "    conf_mat_r = confusion_matrix(y_validate[:val_no_samples,0], y_pred)\n",
    "    confusion_matrices_r.append(conf_mat_r)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 200, 500, 1000, 2000, 5000, 10000]\n",
      "[0.6774422903730388, 0.7132767692088923, 0.7089633597193914, 0.7188699815139593, 0.7270227994501588, 0.7345594160307153, 0.735744418637721]\n"
     ]
    }
   ],
   "source": [
    "print(no_samples_array)\n",
    "print(accuracies_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### benchmarking - rgb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples:  100\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.675830686827511\n",
      "Confusion matrix: \n",
      " [[6830   84   16  169   38   36   77   44   13 1429]\n",
      " [ 531    5    1    7    0    1   15    4    0  189]\n",
      " [ 328    1    1    1    2    7    9    4    1  134]\n",
      " [ 201    2    2    0    3    3    8    3    0  101]\n",
      " [ 197    1    0    4    4    3   11    3    1  138]\n",
      " [ 134    1    4    3    0    1    8    2    2  123]\n",
      " [ 143    2    1    2    2    0    6    0    1  123]\n",
      " [ 128    1    1    4    1    2    5    1    1  172]\n",
      " [ 226    3    1    2    0    2   14    1    2  356]\n",
      " [1279   57    0   84    6    8   90    1   21 7408]]\n",
      "# of training samples:  200\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.6957387306252074\n",
      "Confusion matrix: \n",
      " [[7311    0    7    4    0   17    2    3    3 1389]\n",
      " [ 557    0    2    0    0    1    0    0    1  192]\n",
      " [ 358    0    0    0    0    4    0    1    0  125]\n",
      " [ 220    0    0    0    0    0    1    1    0  101]\n",
      " [ 224    0    0    0    0    0    1    1    1  135]\n",
      " [ 149    0    0    0    0    0    1    1    0  127]\n",
      " [ 146    1    0    0    0    0    0    0    0  133]\n",
      " [ 133    0    0    0    0    1    2    1    0  179]\n",
      " [ 249    0    0    0    0    1    2    0    0  355]\n",
      " [1581    1    0    0    0    2    0    0    4 7366]]\n",
      "# of training samples:  500\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7016637436602361\n",
      "Confusion matrix: \n",
      " [[7220    7    0    4   11    2    2   22    1 1467]\n",
      " [ 561    0    1    0    8    0    1    0    1  181]\n",
      " [ 357    0    1    0    2    0    0    0    0  128]\n",
      " [ 212    0    0    0    1    0    1    1    0  108]\n",
      " [ 232    0    0    0    5    0    0    1    0  124]\n",
      " [ 139    0    0    0    4    1    0    1    0  133]\n",
      " [ 147    0    0    0    0    0    0    0    0  133]\n",
      " [ 124    0    0    0    0    0    1    0    0  191]\n",
      " [ 244    0    0    0    1    0    1    2    0  359]\n",
      " [1344    0    0    7    6    1    2   15    3 7576]]\n",
      "# of training samples:  1000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7009053419917524\n",
      "Confusion matrix: \n",
      " [[7310    1    0    8    0    7    2    1    0 1407]\n",
      " [ 563    0    0    1    0    1    0    0    0  188]\n",
      " [ 354    0    0    1    0    0    0    0    0  133]\n",
      " [ 218    0    0    0    0    0    0    0    0  105]\n",
      " [ 231    0    0    1    0    0    0    0    0  130]\n",
      " [ 141    0    0    0    0    0    0    0    0  137]\n",
      " [ 146    1    0    1    0    0    0    0    0  132]\n",
      " [ 124    0    0    0    0    0    0    0    0  192]\n",
      " [ 240    1    0    1    0    0    0    0    0  365]\n",
      " [1465    0    0   11    0    0    0    1    0 7477]]\n",
      "# of training samples:  2000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7051239512726928\n",
      "Confusion matrix: \n",
      " [[7287    3    0    1    4    1    0    0    0 1440]\n",
      " [ 566    0    0    2    0    0    0    0    0  185]\n",
      " [ 357    0    0    0    0    0    0    0    0  131]\n",
      " [ 216    0    0    0    0    0    0    0    0  107]\n",
      " [ 227    0    0    0    0    0    0    0    1  134]\n",
      " [ 141    0    0    0    1    0    0    0    1  135]\n",
      " [ 143    0    0    1    0    0    0    0    0  136]\n",
      " [ 119    0    0    0    0    0    0    0    0  197]\n",
      " [ 239    0    0    0    1    0    0    0    0  367]\n",
      " [1359    2    0    1    0    0    0    0    3 7589]]\n",
      "# of training samples:  5000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7137981703559748\n",
      "Confusion matrix: \n",
      " [[7396    0    1    1    0    1    0    0    0 1337]\n",
      " [ 565    0    0    0    0    0    0    0    0  188]\n",
      " [ 351    0    0    0    0    0    0    0    0  137]\n",
      " [ 212    0    0    0    0    0    0    0    0  111]\n",
      " [ 221    0    0    0    0    1    0    1    1  138]\n",
      " [ 139    0    0    0    0    1    0    1    1  136]\n",
      " [ 141    0    0    0    0    0    0    0    1  138]\n",
      " [ 120    0    0    0    0    1    0    0    0  195]\n",
      " [ 226    0    0    0    0    0    0    0    0  381]\n",
      " [1291    0    0    0    0    1    0    0    0 7662]]\n",
      "# of training samples:  10000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7137981703559748\n",
      "Confusion matrix: \n",
      " [[7387    0    0    0    4    1    0    0    0 1344]\n",
      " [ 568    0    0    0    0    0    0    0    0  185]\n",
      " [ 357    0    0    0    1    0    0    0    0  130]\n",
      " [ 219    0    0    0    0    0    0    0    0  104]\n",
      " [ 229    0    0    0    0    0    0    0    0  133]\n",
      " [ 144    0    0    0    0    1    0    0    0  133]\n",
      " [ 147    0    0    0    0    0    0    0    0  133]\n",
      " [ 118    0    0    0    0    0    0    0    0  198]\n",
      " [ 230    0    0    0    0    0    1    0    0  376]\n",
      " [1282    0    0    0    0    0    1    0    0 7671]]\n"
     ]
    }
   ],
   "source": [
    "## Benchmark classification of Sentinel-2 RGB data using sklearn RandomForestClassifier\n",
    "\n",
    "# Train/fit the model and predict results for different numbers of samples\n",
    "no_samples_array = [100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "#no_samples_array = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 5000, 10000, 20000, 60000]\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=100, bootstrap=False, class_weight='balanced')\n",
    "\n",
    "#select only RGB data\n",
    "x_train_rgb = x_train[:, bands.index('B2')*no_pixels:(bands.index('B4') + 1)*no_pixels]\n",
    "x_validate_rgb = x_validate[:, bands.index('B2')*no_pixels:(bands.index('B4') + 1)*no_pixels]\n",
    "\n",
    "for no_samples in no_samples_array:\n",
    "    print(\"# of training samples: \", no_samples)\n",
    "    \n",
    "    #val_no_samples = min(int(no_samples/3), no_records_validate)\n",
    "    val_no_samples = no_records_validate\n",
    "    print(\"# of validation samples: \", val_no_samples)\n",
    "    \n",
    "    clf.fit(x_train_rgb[:no_samples, :],y_train[:no_samples,0]) #first column of y: tree cover label\n",
    "    y_pred = clf.predict(x_validate_rgb[:val_no_samples,:])\n",
    "\n",
    "    # evaluate accuracy\n",
    "    acc = clf.score(x_validate_rgb[:val_no_samples,:],\\\n",
    "                    y_validate[:val_no_samples,0])\n",
    "    accuracies.append(acc)\n",
    "    print(\"Accuracy score: \", acc)\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_validate[:val_no_samples,0], y_pred)\n",
    "    confusion_matrices.append(conf_mat)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
