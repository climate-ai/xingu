{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentinel-2 image patches of 7x7 pixels for 10 bands including labels \\\n",
    "\\\n",
    "index files: https://drive.google.com/open?id=14o0eu_UN8RZW68HGR0xHA3es9p_gmuw1 \\\n",
    "training data: https://drive.google.com/open?id=17njNHAyoexj8WmThKfdQzVr18bevGVZ3 \\\n",
    "validation data: https://drive.google.com/open?id=1TtfVv4JomTJW1CKTCX2o4QgUnkoD9iu1 \\\n",
    "testing data: https://drive.google.com/open?id=1RwkC-KitWSeCbLpMhlq7OAlWJgtYx9PS \\\n",
    "\\\n",
    "data format: TFRecord files with featureDict format as defined below, each file containing ca. 20 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "import png\n",
    "import matplotlib.pyplot as plt\n",
    "#import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()\n",
    "try:\n",
    "    tf.enable_eager_execution()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and parse TFRecord data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "## Define files' paths for TFRecord data\n",
    "\n",
    "filenames_train = []\n",
    "filenames_validate = []\n",
    "filenames_test = []\n",
    "\n",
    "no_files_train = 3000\n",
    "no_files_validate = 1000\n",
    "no_files_test = 1000\n",
    "\n",
    "no_records_train = 62434\n",
    "no_records_validate = 21097\n",
    "no_records_test = 21189\n",
    "\n",
    "for i in range(no_files_train):\n",
    "    filenames_train.append(\"../data/EE_data/EE_data_training/train_patches_\"+\"{0:04}\".format(i)+\".tfrecord\") \n",
    "\n",
    "for i in range(no_files_validate):\n",
    "    filenames_validate.append(\"../data/EE_data/EE_data_validation/validate_patches_\"+\"{0:04}\".format(i)+\".tfrecord\")\n",
    "    \n",
    "for i in range(no_files_validate):\n",
    "    filenames_test.append(\"../data/EE_data/EE_data_testing/test_patches_\"+\"{0:04}\".format(i)+\".tfrecord\") \n",
    "    \n",
    "print(len(filenames_train))\n",
    "print(len(filenames_validate))\n",
    "print(len(filenames_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define dictionary with features in TFRecord data\n",
    "\n",
    "bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
    "label_names = ['vegetation_elementstree_element_cover_label', \\\n",
    "                'vegetation_elementsshrub_element_cover_label', \\\n",
    "                'vegetation_elementspalm_element_cover_label', \\\n",
    "                'vegetation_elementsbamboo_element_cover_label', \\\n",
    "                'vegetation_elementscrop_element_cover_label', \\\n",
    "                'infrastructure_elementshouse_element_cover_label', \\\n",
    "                'infrastructure_elementsother_buildings_element_cover_label', \\\n",
    "                'infrastructure_elementspaved_road_element_cover_label', \\\n",
    "                'infrastructure_elementsunpaved_road_element_cover_label', \\\n",
    "                'water_bodieslake_water_cover_label', \\\n",
    "                'water_bodiesriver_water_cover_label', \\\n",
    "                'total_water_bodies_cover_label']\n",
    "\n",
    "featureDict = {}\n",
    "featureDict['public_id'] = tf.io.FixedLenFeature(shape=[1], dtype=tf.string)\n",
    "for band in bands:\n",
    "    featureDict[band] = tf.io.FixedLenFeature(shape=[7,7], dtype=tf.float32,\\\n",
    "                            default_value=tf.zeros([7,7], dtype=tf.float32))\n",
    "for label_name in label_names:\n",
    "    featureDict[label_name] = tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "#print(featureDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import train, validation and test datasets from TFRecord files\n",
    "\n",
    "dataset_train = tf.data.TFRecordDataset(filenames_train)\n",
    "dataset_validate = tf.data.TFRecordDataset(filenames_validate)\n",
    "dataset_test = tf.data.TFRecordDataset(filenames_test)\n",
    "\n",
    "#for i, raw_record in enumerate(dataset_train.take(1)):\n",
    "#    example = tf.train.Example()\n",
    "#    example.ParseFromString(raw_record.numpy())\n",
    "#    print(i)\n",
    "#    print(example)\n",
    "\n",
    "parsedDataset_train = dataset_train.map(lambda example: tf.io.parse_single_example(example, featureDict))\n",
    "parsedDataset_validate = dataset_validate.map(lambda example: tf.io.parse_single_example(example, featureDict))\n",
    "parsedDataset_test = dataset_test.map(lambda example: tf.io.parse_single_example(example, featureDict))\n",
    "\n",
    "\n",
    "#print(parsedDataset_train)\n",
    "#for i, parsed_record in enumerate(parsedDataset_train.take(1)):\n",
    "#    print(i)\n",
    "#    print(repr(parsed_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export tensorflow dataset into numpy arrays\n",
    "\n",
    "def _parse_for_export_(serialized_example):\n",
    "    example = tf.parse_single_example(serialized_example, featureDict)\n",
    "    d = {}\n",
    "    for band in bands:\n",
    "        d[band] = example[band]\n",
    "        d[band] = tf.reshape(example[band], (49,))\n",
    "    for label in label_names:\n",
    "        d[label] = example[label]\n",
    "        d[label] = tf.cast(example[label], tf.int32)\n",
    "    d['public_id'] = tf.cast(example['public_id'], tf.string)\n",
    "    return d\n",
    "\n",
    "def input_fn_export(filenames = filenames_train):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_for_export_(x))\n",
    "    return tfrecord_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62434, 490)\n",
      "(62434, 12)\n",
      "(1, 1)\n",
      "(62434, 490)\n",
      "(62434, 12)\n",
      "(62434, 1)\n"
     ]
    }
   ],
   "source": [
    "# Export training data to numpy arrays\n",
    "dataset_train_for_export = input_fn_export(filenames_train)\n",
    "numpy_dataset_train = list(dataset_train_for_export.as_numpy_iterator())\n",
    "\n",
    "#list_of_features_0 = [np.asarray(numpy_dataset_train[0][band], dtype=np.float32).reshape((1,-1)) for band in bands]\n",
    "#x_train = np.concatenate(list_of_features_0,axis = 1)\n",
    "print(x_train.shape)\n",
    "\n",
    "#list_of_labels_0 = [np.asarray(numpy_dataset_train[0][label], dtype=np.int32).reshape((1,-1)) for label in label_names]\n",
    "#y_train = np.concatenate(list_of_labels_0,axis = 1)\n",
    "print(y_train.shape)\n",
    "\n",
    "id_train = np.asarray(numpy_dataset_train[0]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "print(id_train.shape)\n",
    "\n",
    "for i in range(1, no_records_train):\n",
    "#for i in range(1, 30):\n",
    "#    new_row = np.concatenate([np.asarray(numpy_dataset_train[i][band],\\\n",
    "#                              dtype=np.float32).reshape((1,-1)) for band in bands], axis = 1)\n",
    "#    x_train = np.concatenate((x_train, new_row), axis = 0)\n",
    "#    new_row = np.concatenate([np.asarray(numpy_dataset_train[i][label],\\\n",
    "#                              dtype=np.int32).reshape((1,-1)) for label in label_names], axis = 1)\n",
    "#    y_train = np.concatenate((y_train, new_row), axis = 0)\n",
    "    \n",
    "    new_row = np.asarray(numpy_dataset_train[i]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "    id_train = np.concatenate((id_train, new_row), axis = 0)\n",
    "    \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(id_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21097, 490)\n",
      "(21097, 12)\n",
      "(1, 1)\n",
      "(21097, 490)\n",
      "(21097, 12)\n",
      "(21097, 1)\n"
     ]
    }
   ],
   "source": [
    "# Export validation data to numpy arrays\n",
    "dataset_validate_for_export = input_fn_export(filenames_validate)\n",
    "numpy_dataset_validate = list(dataset_validate_for_export.as_numpy_iterator())\n",
    "\n",
    "#list_of_features_0 = [np.asarray(numpy_dataset_validate[0][band], dtype=np.float32).reshape((1,-1)) for band in bands]\n",
    "#x_validate = np.concatenate(list_of_features_0,axis = 1)\n",
    "print(x_validate.shape)\n",
    "\n",
    "#list_of_labels_0 = [np.asarray(numpy_dataset_validate[0][label], dtype=np.int32).reshape((1,-1)) for label in label_names]\n",
    "#y_validate = np.concatenate(list_of_labels_0,axis = 1)\n",
    "print(y_validate.shape)\n",
    "\n",
    "id_validate = np.asarray(numpy_dataset_validate[0]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "print(id_validate.shape)\n",
    "\n",
    "for i in range(1, no_records_validate):\n",
    "#for i in range(1, 30):\n",
    "#    new_row = np.concatenate([np.asarray(numpy_dataset_validate[i][band],\\\n",
    "#                              dtype=np.float32).reshape((1,-1)) for band in bands], axis = 1)\n",
    "#    x_validate = np.concatenate((x_validate, new_row), axis = 0)\n",
    "    \n",
    "#    new_row = np.concatenate([np.asarray(numpy_dataset_validate[i][label],\\\n",
    "#                              dtype=np.int32).reshape((1,-1)) for label in label_names], axis = 1)\n",
    "#    y_validate = np.concatenate((y_validate, new_row), axis = 0)\n",
    "    \n",
    "    new_row = np.asarray(numpy_dataset_validate[i]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "    id_validate = np.concatenate((id_validate, new_row), axis = 0)\n",
    "    \n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(id_validate.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 490)\n",
      "(1, 12)\n",
      "(1, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-9bd8c59af21d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     new_row = np.concatenate([np.asarray(numpy_dataset_test[i][band],\\\n\u001b[1;32m     19\u001b[0m                               dtype=np.float32).reshape((1,-1)) for band in bands], axis = 1)\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     new_row = np.concatenate([np.asarray(numpy_dataset_test[i][label],\\\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Export test data to numpy arrays\n",
    "dataset_test_for_export = input_fn_export(filenames_test)\n",
    "numpy_dataset_test = list(dataset_test_for_export.as_numpy_iterator())\n",
    "\n",
    "#list_of_features_0 = [np.asarray(numpy_dataset_test[0][band], dtype=np.float32).reshape((1,-1)) for band in bands]\n",
    "#x_test = np.concatenate(list_of_features_0,axis = 1)\n",
    "print(x_test.shape)\n",
    "\n",
    "#list_of_labels_0 = [np.asarray(numpy_dataset_test[0][label], dtype=np.int32).reshape((1,-1)) for label in label_names]\n",
    "#y_test = np.concatenate(list_of_labels_0,axis = 1)\n",
    "print(y_test.shape)\n",
    "\n",
    "id_test = np.asarray(numpy_dataset_test[0]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "print(id_test.shape)\n",
    "\n",
    "for i in range(1, no_records_test):\n",
    "#for i in range(1, 30):\n",
    "#    new_row = np.concatenate([np.asarray(numpy_dataset_test[i][band],\\\n",
    "#                              dtype=np.float32).reshape((1,-1)) for band in bands], axis = 1)\n",
    "#    x_test = np.concatenate((x_test, new_row), axis = 0)\n",
    "#    \n",
    "#    new_row = np.concatenate([np.asarray(numpy_dataset_test[i][label],\\\n",
    "#                              dtype=np.int32).reshape((1,-1)) for label in label_names], axis = 1)\n",
    "#    y_test = np.concatenate((y_test, new_row), axis = 0)\n",
    "    \n",
    "    new_row = np.asarray(numpy_dataset_test[i]['public_id'], dtype=np.unicode_).reshape((1,-1))\n",
    "    id_test = np.concatenate((id_test, new_row), axis = 0)\n",
    "    \n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(id_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['GLU0452795']\n",
      " ['GLU0202549']\n",
      " ['GLU0471188']\n",
      " ...\n",
      " ['GLU0340234']\n",
      " ['GLU0356918']\n",
      " ['GLU0334555']]\n"
     ]
    }
   ],
   "source": [
    "print(id_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save data as numpy arrays on disk\n",
    "\n",
    "np.save('../data/EE_data/x_train.npy', x_train)\n",
    "np.save('../data/EE_data/y_train.npy', y_train)\n",
    "np.save('../data/EE_data/id_train.npy', id_train)\n",
    "\n",
    "np.save('../data/EE_data/x_validate.npy', x_validate)\n",
    "np.save('../data/EE_data/y_validate.npy', y_validate)\n",
    "np.save('../data/EE_data/id_validate.npy', id_validate)\n",
    "\n",
    "#np.save('../data/EE_data/x_test.npy', x_test)\n",
    "#np.save('../data/EE_data/y_test.npy', y_test)\n",
    "#np.save('../data/EE_data/id_test.npy', id_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse TFRecord dataset functions for classification pipeline\n",
    "\n",
    "def _parse_(serialized_example):\n",
    "    example = tf.parse_single_example(serialized_example, featureDict)\n",
    "    d = {}\n",
    "    for band in bands:\n",
    "        d[band] = example[band]\n",
    "        #d[band] = tf.reshape(example[band], (49,))\n",
    "        \n",
    "    label = tf.cast(example['vegetation_elementstree_element_cover_label'], tf.int32)\n",
    "    return d, label\n",
    "\n",
    "\n",
    "# Resampler to balance the training dataset\n",
    "resampler = tf.data.experimental.rejection_resample(\n",
    "    class_func, target_dist=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "\n",
    "no_records_train = 62434\n",
    "no_records_validate = 21097\n",
    "no_records_test = 21189\n",
    "\n",
    "def train_input_fn(batch_size=32, no_records = no_records_train):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(filenames_train).take(no_records)\n",
    "    tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).shuffle(True).batch(batch_size)\n",
    "    tfrecord_iterator = tfrecord_dataset.make_one_shot_iterator()\n",
    "    return tfrecord_iterator.get_next()\n",
    "\n",
    "def train_input_fn_2(batch_size=32, no_records = no_records_train, resample = False):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(filenames_train).take(no_records)\n",
    "    tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).shuffle(True).batch(batch_size)\n",
    "    if resample == True:\n",
    "        tfrecord_dataset = tfrecord_dataset.unbatch().apply(resampler).batch(batch_size)\n",
    "        #tfrecord_dataset = tfrecord_dataset.map(lambda extra_label, features_and_label: features_and_label)\n",
    "    return tfrecord_dataset\n",
    "\n",
    "def validate_input_fn(batch_size=32, no_records = no_records_validate):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(filenames_validate).take(no_records)\n",
    "    tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).shuffle(True).batch(batch_size)\n",
    "    tfrecord_iterator = tfrecord_dataset.make_one_shot_iterator()\n",
    "    return tfrecord_iterator.get_next()\n",
    "\n",
    "def test_input_fn(batch_size=32, no_records = no_records_test):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(filenames_test).take(no_records)\n",
    "    tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).shuffle(True).batch(batch_size)\n",
    "    tfrecord_iterator = tfrecord_dataset.make_one_shot_iterator()\n",
    "    return tfrecord_iterator.get_next()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse TFRecord dataset to compute confusion matrix later\n",
    "\n",
    "def validate_input_fn_labels(batch_size=32, no_records = no_records_validate):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(filenames_validate).take(no_records)\n",
    "    tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).batch(batch_size)\n",
    "    tfrecord_iterator = tfrecord_dataset.make_one_shot_iterator()\n",
    "    return tfrecord_iterator.get_next()\n",
    "\n",
    "def _parse_label_(serialized_example):\n",
    "    example = tf.parse_single_example(serialized_example, featureDict)\n",
    "    label = tf.cast(example['vegetation_elementstree_element_cover_label'], tf.int32)\n",
    "    return label\n",
    "\n",
    "raw_validation_labels = dataset_validate.map(_parse_label_)\n",
    "\n",
    "#for i, parsed_record in enumerate(raw_labels.take(10)):\n",
    "#    print(i)\n",
    "#    print(repr(parsed_record))\n",
    "\n",
    "validation_labels = []  \n",
    "for raw_label in raw_validation_labels:\n",
    "    raw_label = raw_label.numpy()\n",
    "    validation_labels = validation_labels + raw_label.tolist()\n",
    "\n",
    "print(validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.estimator.Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='B2', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='B3', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='B4', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='B5', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='B6', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='B7', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='B8', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='B8A', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='B11', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='B12', shape=(7, 7), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "for band in bands:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=band, shape=(7,7)))\n",
    "    #feature_columns.append(tf.feature_column.numeric_column(key=band, shape=(49,)))\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmphib1x5oh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "model = tf.estimator.DNNClassifier(\n",
    "    [256,32],\n",
    "    model_dir=model_dir,\n",
    "    n_classes=10,\n",
    "    feature_columns=feature_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/experimental/ops/resampling.py:178 update_estimate_and_tile\n        array_ops.expand_dims(dist, 0), [dist_estimation_batch_size, 1])\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:10411 tile\n        \"Tile\", input=input, multiples=multiples, name=name)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal\n        op_def=op_def)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1786 __init__\n        control_input_ops)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be rank 3 but is rank 2 for 'Tile' (op: 'Tile') with input shapes: [1,1,10], [2].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f4d959288ba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1162\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       features, labels, input_hooks = (\n\u001b[1;32m   1190\u001b[0m           self._get_features_and_labels_from_input_fn(\n\u001b[0;32m-> 1191\u001b[0;31m               input_fn, ModeKeys.TRAIN))\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       estimator_spec = self._call_model_fn(\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     return estimator_util.parse_input_fn_result(\n\u001b[0;32m-> 1028\u001b[0;31m         self._call_input_fn(input_fn, mode))\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extract_batch_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_context'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-f4d959288ba3>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-ea3e9efd7b9e>\u001b[0m in \u001b[0;36mtrain_input_fn\u001b[0;34m(batch_size, no_records, resample)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtfrecord_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfrecord_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0m_parse_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtfrecord_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfrecord_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtfrecord_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfrecord_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mextra_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_and_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures_and_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtfrecord_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfrecord_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transformation_func)\u001b[0m\n\u001b[1;32m   2383\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformation_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transformation_func)\u001b[0m\n\u001b[1;32m   1741\u001b[0m           \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \"\"\"\n\u001b[0;32m-> 1743\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/experimental/ops/resampling.py\u001b[0m in \u001b[0;36m_apply_fn\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       initial_dist_ds = _estimate_initial_dist_ds(\n\u001b[0;32m---> 75\u001b[0;31m           target_dist_t, class_values_ds)\n\u001b[0m\u001b[1;32m     76\u001b[0m       acceptance_and_original_prob_ds = initial_dist_ds.map(\n\u001b[1;32m     77\u001b[0m           lambda initial: _calculate_acceptance_probs_with_mixing(  # pylint: disable=g-long-lambda\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/experimental/ops/resampling.py\u001b[0m in \u001b[0;36m_estimate_initial_dist_ds\u001b[0;34m(target_dist_t, class_values_ds, dist_estimation_batch_size, smoothing_constant)\u001b[0m\n\u001b[1;32m    181\u001b[0m   initial_dist_ds = (class_values_ds.batch(dist_estimation_batch_size)\n\u001b[1;32m    182\u001b[0m                      .apply(scan_ops.scan(initial_examples_per_class_seen,\n\u001b[0;32m--> 183\u001b[0;31m                                           update_estimate_and_tile))\n\u001b[0m\u001b[1;32m    184\u001b[0m                      .unbatch())\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transformation_func)\u001b[0m\n\u001b[1;32m   2383\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformation_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transformation_func)\u001b[0m\n\u001b[1;32m   1741\u001b[0m           \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \"\"\"\n\u001b[0;32m-> 1743\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/experimental/ops/scan_ops.py\u001b[0m in \u001b[0;36m_apply_fn\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    179\u001b[0m   \"\"\"\n\u001b[1;32m    180\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_apply_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ScanDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/experimental/ops/scan_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, initial_state, scan_func, use_default_device)\u001b[0m\n\u001b[1;32m     55\u001b[0m           input_structure=(self._state_structure,\n\u001b[1;32m     56\u001b[0m                            input_dataset.element_spec),\n\u001b[0;32m---> 57\u001b[0;31m           add_to_graph=False)\n\u001b[0m\u001b[1;32m     58\u001b[0m       if not (isinstance(wrapped_func.output_types, collections_abc.Sequence)\n\u001b[1;32m     59\u001b[0m               and len(wrapped_func.output_types) == 2):\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/data/experimental/ops/resampling.py:178 update_estimate_and_tile\n        array_ops.expand_dims(dist, 0), [dist_estimation_batch_size, 1])\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:10411 tile\n        \"Tile\", input=input, multiples=multiples, name=name)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal\n        op_def=op_def)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1786 __init__\n        control_input_ops)\n    /Users/rotti/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be rank 3 but is rank 2 for 'Tile' (op: 'Tile') with input shapes: [1,1,10], [2].\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "model.train(lambda:train_input_fn(32,100,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:35:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmphib1x5oh/model.ckpt-4\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.59132s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:35:46\n",
      "INFO:tensorflow:Saving dict for global step 4: accuracy = 0.43, average_loss = 2.3914309, global_step = 4, loss = 59.785774\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmphib1x5oh/model.ckpt-4\n",
      "accuracy : 0.43\n",
      "average_loss : 2.3914309\n",
      "loss : 59.785774\n",
      "global_step : 4\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(lambda:validate_input_fn(32,100))\n",
    "\n",
    "for key, value in result.items():\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmphib1x5oh/model.ckpt-4\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [-0.5866188   0.58666635 -0.4337511  -0.47269294  0.68251884  2.2297738\n",
      "  0.32045525 -0.448139   -0.285868    2.8130026 ]\n",
      "probabilities : [0.01620171 0.05237357 0.01887776 0.01815676 0.05764218 0.27083492\n",
      " 0.04013268 0.0186081  0.02188645 0.48528594]\n",
      "class_ids : [9]\n",
      "classes : [b'9']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n"
     ]
    }
   ],
   "source": [
    "for pred in model.predict(lambda:validate_input_fn(32,100)):\n",
    "    for key, value in pred.items():\n",
    "        print(key, \":\", value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzsojrht3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzsojrht3/model.ckpt.\n",
      "INFO:tensorflow:loss = 72.893585, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 4 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzsojrht3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.547167.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:35:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzsojrht3/model.ckpt-4\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.59140s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:35:51\n",
      "INFO:tensorflow:Saving dict for global step 4: accuracy = 0.43, average_loss = 1.684505, global_step = 4, loss = 42.112625\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzsojrht3/model.ckpt-4\n",
      "accuracy : 0.43\n",
      "average_loss : 1.684505\n",
      "loss : 42.112625\n",
      "global_step : 4\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzsojrht3/model.ckpt-4\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 1.1383526  -0.6041658  -0.46840593 -0.4791793  -0.06532515  0.48674783\n",
      " -0.00679452 -1.2228913  -0.84656906  1.0579    ]\n",
      "probabilities : [0.2585402  0.04526494 0.05184677 0.05129121 0.07758495 0.1347534\n",
      " 0.08226157 0.02438108 0.03552119 0.23855469]\n",
      "class_ids : [0]\n",
      "classes : [b'0']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp9el9fm_p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp9el9fm_p/model.ckpt.\n",
      "INFO:tensorflow:loss = 73.33514, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 7 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp9el9fm_p/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9.431732.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:35:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp9el9fm_p/model.ckpt-7\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.58259s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:35:55\n",
      "INFO:tensorflow:Saving dict for global step 7: accuracy = 0.43, average_loss = 1.5801442, global_step = 7, loss = 39.503605\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp9el9fm_p/model.ckpt-7\n",
      "accuracy : 0.43\n",
      "average_loss : 1.5801442\n",
      "loss : 39.503605\n",
      "global_step : 7\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp9el9fm_p/model.ckpt-7\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 1.0226691  -0.486917   -0.23402971 -0.5650566  -2.4728053  -1.8660051\n",
      " -0.12002596 -0.3954233  -0.24928541  2.6435869 ]\n",
      "probabilities : [0.12995258 0.02871971 0.03698346 0.026561   0.00394203 0.00723185\n",
      " 0.04144945 0.03147134 0.03642353 0.65726507]\n",
      "class_ids : [9]\n",
      "classes : [b'9']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpgm6t2o4r', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpgm6t2o4r/model.ckpt.\n",
      "INFO:tensorflow:loss = 71.23718, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpgm6t2o4r/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9.591812.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpgm6t2o4r/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.66713s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:01\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.43, average_loss = 1.397043, global_step = 10, loss = 34.926075\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpgm6t2o4r/model.ckpt-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.43\n",
      "average_loss : 1.397043\n",
      "loss : 34.926075\n",
      "global_step : 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpgm6t2o4r/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 3.9503834  -0.70422584 -1.2165333  -2.1668704  -2.3301308  -2.9304123\n",
      " -1.0742302  -0.8646345  -0.26395583  3.8505278 ]\n",
      "probabilities : [0.51157296 0.00486896 0.00291705 0.00112776 0.00095789 0.00052555\n",
      " 0.00336315 0.00414736 0.00756212 0.46295717]\n",
      "class_ids : [0]\n",
      "classes : [b'0']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpxwdzxqw1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpxwdzxqw1/model.ckpt.\n",
      "INFO:tensorflow:loss = 71.148056, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 13 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpxwdzxqw1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13.19096.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpxwdzxqw1/model.ckpt-13\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.56699s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:05\n",
      "INFO:tensorflow:Saving dict for global step 13: accuracy = 0.43, average_loss = 1.4046079, global_step = 13, loss = 35.115196\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpxwdzxqw1/model.ckpt-13\n",
      "accuracy : 0.43\n",
      "average_loss : 1.4046079\n",
      "loss : 35.115196\n",
      "global_step : 13\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpxwdzxqw1/model.ckpt-13\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 3.714154    1.2945212   0.6030214  -1.5324165  -1.2761198  -1.8479387\n",
      " -2.517948   -0.32011938 -0.6353598   4.194675  ]\n",
      "probabilities : [0.35728216 0.03178178 0.01591709 0.00188129 0.00243088 0.00137222\n",
      " 0.00070217 0.00632337 0.00461362 0.5776954 ]\n",
      "class_ids : [9]\n",
      "classes : [b'9']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpfz8au2_7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpfz8au2_7/model.ckpt.\n",
      "INFO:tensorflow:loss = 73.15248, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 16 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpfz8au2_7/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 23.732393.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpfz8au2_7/model.ckpt-16\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.43020s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:09\n",
      "INFO:tensorflow:Saving dict for global step 16: accuracy = 0.43, average_loss = 1.3198447, global_step = 16, loss = 32.996117\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpfz8au2_7/model.ckpt-16\n",
      "accuracy : 0.43\n",
      "average_loss : 1.3198447\n",
      "loss : 32.996117\n",
      "global_step : 16\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpfz8au2_7/model.ckpt-16\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 2.7232628  -0.50525045 -1.430313   -0.9647952  -1.1744752  -1.9112716\n",
      " -1.1200808  -1.715897   -0.89591193  2.357735  ]\n",
      "probabilities : [0.5364213  0.02125106 0.00842618 0.01342155 0.01088278 0.00520899\n",
      " 0.01149114 0.00633291 0.01437866 0.37218535]\n",
      "class_ids : [0]\n",
      "classes : [b'0']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp2haeckof', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp2haeckof/model.ckpt.\n",
      "INFO:tensorflow:loss = 73.587845, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 19 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp2haeckof/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 37.794704.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp2haeckof/model.ckpt-19\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.49891s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:14\n",
      "INFO:tensorflow:Saving dict for global step 19: accuracy = 0.67, average_loss = 1.3059692, global_step = 19, loss = 32.64923\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 19: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp2haeckof/model.ckpt-19\n",
      "accuracy : 0.67\n",
      "average_loss : 1.3059692\n",
      "loss : 32.64923\n",
      "global_step : 19\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp2haeckof/model.ckpt-19\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 2.8281229   0.04063772 -0.99595314 -0.14247487 -1.0636455  -2.1776915\n",
      " -0.6675747  -1.9608477  -0.12758835  2.738039  ]\n",
      "probabilities : [0.46160802 0.02842392 0.01008088 0.02366787 0.00942106 0.00309226\n",
      " 0.01399946 0.00384105 0.02402284 0.4218426 ]\n",
      "class_ids : [0]\n",
      "classes : [b'0']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6tj4vsii', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6tj4vsii/model.ckpt.\n",
      "INFO:tensorflow:loss = 72.85536, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 22 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6tj4vsii/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 47.8304.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6tj4vsii/model.ckpt-22\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.50302s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:17\n",
      "INFO:tensorflow:Saving dict for global step 22: accuracy = 0.76, average_loss = 1.3507732, global_step = 22, loss = 33.76933\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6tj4vsii/model.ckpt-22\n",
      "accuracy : 0.76\n",
      "average_loss : 1.3507732\n",
      "loss : 33.76933\n",
      "global_step : 22\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6tj4vsii/model.ckpt-22\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 1.4416261 -0.9391213 -1.5787207 -1.2948343 -1.2670228 -2.7274668\n",
      " -1.2306539 -2.14733   -1.0253888  1.5023488]\n",
      "probabilities : [0.39489457 0.03652041 0.01926466 0.0255889  0.02631055 0.00610755\n",
      " 0.02728505 0.01090981 0.03350196 0.41961664]\n",
      "class_ids : [9]\n",
      "classes : [b'9']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpacd3mup_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpacd3mup_/model.ckpt.\n",
      "INFO:tensorflow:loss = 73.74425, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 25 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpacd3mup_/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 45.97996.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpacd3mup_/model.ckpt-25\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.73890s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:22\n",
      "INFO:tensorflow:Saving dict for global step 25: accuracy = 0.73, average_loss = 1.2001129, global_step = 25, loss = 30.002823\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpacd3mup_/model.ckpt-25\n",
      "accuracy : 0.73\n",
      "average_loss : 1.2001129\n",
      "loss : 30.002823\n",
      "global_step : 25\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpacd3mup_/model.ckpt-25\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 2.350064    0.24656393 -1.087261   -0.7392673  -1.0550946  -1.7467916\n",
      " -0.7883813  -2.2287488  -0.15177906  2.832456  ]\n",
      "probabilities : [0.33277497 0.04060805 0.01069891 0.01515204 0.01104864 0.00553234\n",
      " 0.01442584 0.00341663 0.02726553 0.5390771 ]\n",
      "class_ids : [9]\n",
      "classes : [b'9']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp34thhpj2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp34thhpj2/model.ckpt.\n",
      "INFO:tensorflow:loss = 73.54076, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 29 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp34thhpj2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9.339104.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp34thhpj2/model.ckpt-29\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.45557s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:26\n",
      "INFO:tensorflow:Saving dict for global step 29: accuracy = 0.69, average_loss = 1.4809692, global_step = 29, loss = 37.02423\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 29: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp34thhpj2/model.ckpt-29\n",
      "accuracy : 0.69\n",
      "average_loss : 1.4809692\n",
      "loss : 37.02423\n",
      "global_step : 29\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp34thhpj2/model.ckpt-29\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 0.5924467  -0.2318365  -1.0799457  -0.67834926 -1.1507468  -1.6774099\n",
      " -1.1535672  -0.7484893  -0.9234782   0.8643845 ]\n",
      "probabilities : [0.24076535 0.10558745 0.04521506 0.06756073 0.04212449 0.02487756\n",
      " 0.04200585 0.06298438 0.05287327 0.3160058 ]\n",
      "class_ids : [9]\n",
      "classes : [b'9']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpt0xou2j5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpt0xou2j5/model.ckpt.\n",
      "INFO:tensorflow:loss = 73.327515, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 32 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpt0xou2j5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.95133.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpt0xou2j5/model.ckpt-32\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.44158s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:30\n",
      "INFO:tensorflow:Saving dict for global step 32: accuracy = 0.75, average_loss = 1.1612095, global_step = 32, loss = 29.030235\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 32: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpt0xou2j5/model.ckpt-32\n",
      "accuracy : 0.75\n",
      "average_loss : 1.1612095\n",
      "loss : 29.030235\n",
      "global_step : 32\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpt0xou2j5/model.ckpt-32\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 2.2879593   0.5438425  -0.6127039  -0.45803833 -0.6990291  -1.2844648\n",
      " -0.7157872  -1.0997428  -0.02807464  2.545378  ]\n",
      "probabilities : [0.35110697 0.06137326 0.01930623 0.02253553 0.01770952 0.00986178\n",
      " 0.01741522 0.01186258 0.03464165 0.45418727]\n",
      "class_ids : [9]\n",
      "classes : [b'9']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp5in3s6yg', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp5in3s6yg/model.ckpt.\n",
      "INFO:tensorflow:loss = 76.46532, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 63 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp5in3s6yg/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20.914494.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp5in3s6yg/model.ckpt-63\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.54442s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:35\n",
      "INFO:tensorflow:Saving dict for global step 63: accuracy = 0.43, average_loss = 1.3120264, global_step = 63, loss = 32.80066\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 63: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp5in3s6yg/model.ckpt-63\n",
      "accuracy : 0.43\n",
      "average_loss : 1.3120264\n",
      "loss : 32.80066\n",
      "global_step : 63\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp5in3s6yg/model.ckpt-63\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 2.412913    0.11701782 -0.90175813 -0.70753634 -1.4659326  -1.9632181\n",
      " -1.7138586  -1.4749655  -0.68589747  2.2652278 ]\n",
      "probabilities : [0.46321338 0.04663226 0.01683595 0.020445   0.00957679 0.0058244\n",
      " 0.00747389 0.00949067 0.02089223 0.3996154 ]\n",
      "class_ids : [0]\n",
      "classes : [b'0']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpz58gcbri', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpz58gcbri/model.ckpt.\n",
      "INFO:tensorflow:loss = 73.029106, step = 1\n",
      "INFO:tensorflow:global_step/sec: 94.6522\n",
      "INFO:tensorflow:loss = 30.320961, step = 101 (1.058 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 157 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpz58gcbri/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.380632.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpz58gcbri/model.ckpt-157\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.45645s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:40\n",
      "INFO:tensorflow:Saving dict for global step 157: accuracy = 0.77, average_loss = 0.9671634, global_step = 157, loss = 24.179085\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 157: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpz58gcbri/model.ckpt-157\n",
      "accuracy : 0.77\n",
      "average_loss : 0.9671634\n",
      "loss : 24.179085\n",
      "global_step : 157\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpz58gcbri/model.ckpt-157\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 1.4665189  -0.5201946  -0.8357804  -1.2588311  -1.3251468  -1.2243607\n",
      " -1.4424839  -1.036588   -0.75967616  1.8714265 ]\n",
      "probabilities : [0.31493083 0.04319132 0.03150209 0.0206353  0.01931124 0.02135901\n",
      " 0.0171732  0.02577091 0.03399312 0.47213295]\n",
      "class_ids : [9]\n",
      "classes : [b'9']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6_fbm6lf', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6_fbm6lf/model.ckpt.\n",
      "INFO:tensorflow:loss = 76.76326, step = 1\n",
      "INFO:tensorflow:global_step/sec: 127.026\n",
      "INFO:tensorflow:loss = 29.441319, step = 101 (0.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.215\n",
      "INFO:tensorflow:loss = 33.084076, step = 201 (0.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5049\n",
      "INFO:tensorflow:loss = 31.10693, step = 301 (1.197 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 313 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6_fbm6lf/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 17.705147.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6_fbm6lf/model.ckpt-313\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.51746s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:47\n",
      "INFO:tensorflow:Saving dict for global step 313: accuracy = 0.77, average_loss = 0.9421164, global_step = 313, loss = 23.55291\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 313: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6_fbm6lf/model.ckpt-313\n",
      "accuracy : 0.77\n",
      "average_loss : 0.9421164\n",
      "loss : 23.55291\n",
      "global_step : 313\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp6_fbm6lf/model.ckpt-313\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 1.2761943  -0.4006747  -0.826542   -1.0836267  -0.97881114 -1.138594\n",
      " -1.0222001  -0.8336092  -0.43500516  1.5724953 ]\n",
      "probabilities : [0.29895523 0.0558922  0.03650895 0.02823247 0.03135233 0.02672249\n",
      " 0.03002106 0.03625185 0.05400597 0.4020574 ]\n",
      "class_ids : [9]\n",
      "classes : [b'9']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzmn92db0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzmn92db0/model.ckpt.\n",
      "INFO:tensorflow:loss = 76.21069, step = 1\n",
      "INFO:tensorflow:global_step/sec: 112.171\n",
      "INFO:tensorflow:loss = 28.6836, step = 101 (0.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.585\n",
      "INFO:tensorflow:loss = 32.61222, step = 201 (0.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.008\n",
      "INFO:tensorflow:loss = 30.696041, step = 301 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.661\n",
      "INFO:tensorflow:loss = 34.34546, step = 401 (1.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.3904\n",
      "INFO:tensorflow:loss = 45.366066, step = 501 (1.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9267\n",
      "INFO:tensorflow:loss = 46.721313, step = 601 (1.302 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 625 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzmn92db0/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 29.09676.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:36:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzmn92db0/model.ckpt-625\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.52825s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:36:57\n",
      "INFO:tensorflow:Saving dict for global step 625: accuracy = 0.77, average_loss = 0.951124, global_step = 625, loss = 23.778101\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 625: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzmn92db0/model.ckpt-625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.77\n",
      "average_loss : 0.951124\n",
      "loss : 23.778101\n",
      "global_step : 625\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpzmn92db0/model.ckpt-625\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 1.3085629  -0.25141612 -0.7394431  -1.0347878  -1.3300099  -1.0913024\n",
      " -1.4111291  -1.1404884  -0.847273    1.0955732 ]\n",
      "probabilities : [0.37403136 0.07859914 0.04824699 0.03590904 0.02672948 0.03393594\n",
      " 0.02464681 0.03230714 0.04331521 0.30227888]\n",
      "class_ids : [0]\n",
      "classes : [b'0']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp7te64r3v', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp7te64r3v/model.ckpt.\n",
      "INFO:tensorflow:loss = 75.09389, step = 1\n",
      "INFO:tensorflow:global_step/sec: 127.88\n",
      "INFO:tensorflow:loss = 29.126877, step = 101 (0.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.176\n",
      "INFO:tensorflow:loss = 32.194313, step = 201 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.523\n",
      "INFO:tensorflow:loss = 31.670372, step = 301 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.512\n",
      "INFO:tensorflow:loss = 34.09522, step = 401 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.035\n",
      "INFO:tensorflow:loss = 44.775597, step = 501 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.941\n",
      "INFO:tensorflow:loss = 46.340942, step = 601 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.0882\n",
      "INFO:tensorflow:loss = 34.975624, step = 701 (1.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.7999\n",
      "INFO:tensorflow:loss = 27.056519, step = 801 (1.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2424\n",
      "INFO:tensorflow:loss = 26.716969, step = 901 (1.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.3142\n",
      "INFO:tensorflow:loss = 22.236767, step = 1001 (1.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8922\n",
      "INFO:tensorflow:loss = 24.242348, step = 1101 (1.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9825\n",
      "INFO:tensorflow:loss = 32.488487, step = 1201 (1.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6639\n",
      "INFO:tensorflow:loss = 33.078224, step = 1301 (1.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7995\n",
      "INFO:tensorflow:loss = 30.92503, step = 1401 (1.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.1876\n",
      "INFO:tensorflow:loss = 40.579735, step = 1501 (1.174 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1563 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp7te64r3v/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 17.740835.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:37:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp7te64r3v/model.ckpt-1563\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.44599s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:37:15\n",
      "INFO:tensorflow:Saving dict for global step 1563: accuracy = 0.79, average_loss = 0.91377014, global_step = 1563, loss = 22.844254\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1563: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp7te64r3v/model.ckpt-1563\n",
      "accuracy : 0.79\n",
      "average_loss : 0.91377014\n",
      "loss : 22.844254\n",
      "global_step : 1563\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp7te64r3v/model.ckpt-1563\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 1.6944404  -0.23859465 -0.33058035 -0.82414126 -0.915348   -0.9640836\n",
      " -1.0371091  -1.1037216  -0.63866323  0.9642943 ]\n",
      "probabilities : [0.45336092 0.0656051  0.05983961 0.03652902 0.03334474 0.03175863\n",
      " 0.0295221  0.02761962 0.0439734  0.21844679]\n",
      "class_ids : [0]\n",
      "classes : [b'0']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpvdsb9m3s', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpvdsb9m3s/model.ckpt.\n",
      "INFO:tensorflow:loss = 75.07734, step = 1\n",
      "INFO:tensorflow:global_step/sec: 111.913\n",
      "INFO:tensorflow:loss = 29.049103, step = 101 (0.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.604\n",
      "INFO:tensorflow:loss = 32.47888, step = 201 (0.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.241\n",
      "INFO:tensorflow:loss = 32.15419, step = 301 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.379\n",
      "INFO:tensorflow:loss = 34.338753, step = 401 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.915\n",
      "INFO:tensorflow:loss = 45.32682, step = 501 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.727\n",
      "INFO:tensorflow:loss = 46.135544, step = 601 (0.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.5776\n",
      "INFO:tensorflow:loss = 34.907322, step = 701 (1.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2547\n",
      "INFO:tensorflow:loss = 27.45257, step = 801 (1.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.3665\n",
      "INFO:tensorflow:loss = 26.708729, step = 901 (1.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.6275\n",
      "INFO:tensorflow:loss = 22.66158, step = 1001 (1.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7846\n",
      "INFO:tensorflow:loss = 24.60676, step = 1101 (1.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7567\n",
      "INFO:tensorflow:loss = 32.185093, step = 1201 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.0687\n",
      "INFO:tensorflow:loss = 33.347137, step = 1301 (1.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1764\n",
      "INFO:tensorflow:loss = 31.194773, step = 1401 (1.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7367\n",
      "INFO:tensorflow:loss = 41.020115, step = 1501 (1.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.5875\n",
      "INFO:tensorflow:loss = 31.393188, step = 1601 (1.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 31.099277, step = 1701 (1.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1057\n",
      "INFO:tensorflow:loss = 23.547497, step = 1801 (1.217 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1875 into /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpvdsb9m3s/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 35.111504.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-15T08:37:38Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpvdsb9m3s/model.ckpt-1875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.51597s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-15-08:37:39\n",
      "INFO:tensorflow:Saving dict for global step 1875: accuracy = 0.77, average_loss = 0.93333846, global_step = 1875, loss = 23.333462\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1875: /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpvdsb9m3s/model.ckpt-1875\n",
      "accuracy : 0.77\n",
      "average_loss : 0.93333846\n",
      "loss : 23.333462\n",
      "global_step : 1875\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpvdsb9m3s/model.ckpt-1875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "logits : [ 1.6972857  -0.15858954 -0.44436014 -0.64875865 -0.83553916 -1.0595629\n",
      " -1.2830832  -1.0460951  -0.61086094  0.7529435 ]\n",
      "probabilities : [0.4725993  0.07387487 0.05551215 0.04525004 0.0375406  0.03000606\n",
      " 0.0239958  0.03041291 0.04699783 0.18381058]\n",
      "class_ids : [0]\n",
      "classes : [b'0']\n",
      "all_class_ids : [0 1 2 3 4 5 6 7 8 9]\n",
      "all_classes : [b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9']\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "no_samples_array = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 5000, 10000, 20000, 50000, 60000]\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for no_samples in no_samples_array:\n",
    "    model_dir = tempfile.mkdtemp()\n",
    "    model = tf.estimator.DNNClassifier(\n",
    "        [256,32],\n",
    "        model_dir=model_dir,\n",
    "        n_classes=10,\n",
    "        feature_columns=feature_columns,\n",
    "    )\n",
    "    model.train(lambda:train_input_fn(32,no_samples))\n",
    "    result = model.evaluate(lambda:validate_input_fn(32,100))\n",
    "    for key, value in result.items():\n",
    "        print(key, \":\", value)\n",
    "    accuracies.append(result['accuracy'])\n",
    "    for pred in model.predict(lambda:validate_input_fn(32,100)):\n",
    "        for key, value in pred.items():\n",
    "            print(key, \":\", value)\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Classifier\n",
      "[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 5000, 10000, 20000, 50000, 60000]\n",
      "[0.43, 0.43, 0.43, 0.43, 0.43, 0.67, 0.76, 0.73, 0.69, 0.75, 0.43, 0.77, 0.77, 0.77, 0.79, 0.77]\n"
     ]
    }
   ],
   "source": [
    "print('DNN Classifier')\n",
    "print(no_samples_array)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter'> to Tensor. Contents: <DatasetV1Adapter shapes: (1,), types: tf.int32>. Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     86\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 87\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got <DatasetV1Adapter shapes: (1,), types: tf.int32>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-e4adffb78b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mraw_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_validate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0m_parse_label_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    703\u001b[0m       \u001b[0;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0;31m# strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    315\u001b[0m                                          as_ref=False):\n\u001b[1;32m    316\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    294\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    295\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    297\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    545\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    546\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter'> to Tensor. Contents: <DatasetV1Adapter shapes: (1,), types: tf.int32>. Consider casting elements to a supported type."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmpvdsb9m3s/model.ckpt-1875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Tensor(\"confusion_matrix_1/SparseTensorDenseAdd:0\", shape=(10, 10), dtype=int32)\n",
      "Confusion Matrix: \n",
      "\n",
      " [[7797    0    0    0    0    0    0    0    0  939]\n",
      " [ 601    0    0    0    0    0    0    0    0  152]\n",
      " [ 394    0    0    0    0    0    0    0    0   94]\n",
      " [ 230    0    0    0    0    0    0    0    0   93]\n",
      " [ 251    0    0    0    0    0    0    0    0  111]\n",
      " [ 171    0    0    0    0    0    0    0    0  107]\n",
      " [ 170    0    0    0    0    0    0    0    0  110]\n",
      " [ 169    0    0    0    0    0    0    0    0  147]\n",
      " [ 290    0    0    0    0    0    0    0    0  317]\n",
      " [1649    0    0    0    0    0    0    0    0 7305]]\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model.predict(lambda:validate_input_fn_labels(32,no_records_validate))\n",
    "predictions = [p['class_ids'][0] for p in raw_predictions]\n",
    "con_mat = tf.math.confusion_matrix(validation_labels, predictions)\n",
    "print(con_mat)\n",
    "with tf.Session():\n",
    "   print('Confusion Matrix: \\n\\n', tf.Tensor.eval(con_mat,feed_dict=None, session=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### benchmarking - sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples:  100\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.6755936863061098\n",
      "Confusion matrix: \n",
      " [[6981  101   16  126    1   20   41  232    1 1217]\n",
      " [ 499    6    2   11    0    4   11   18    0  202]\n",
      " [ 319    3    1    7    0    4    5    8    0  141]\n",
      " [ 179    2    0    2    0    2    7    7    0  124]\n",
      " [ 187    2    0    6    0    2    4    9    0  152]\n",
      " [ 121    4    0    4    0    1    2    3    0  143]\n",
      " [ 121    5    0    4    0    0    1    4    0  145]\n",
      " [ 109    3    0    7    0    0    4    5    0  188]\n",
      " [ 214    8    0    6    1    2    7    7    0  362]\n",
      " [1372  115    3  134    0    5   43   25    1 7256]]\n",
      "# of training samples:  200\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7153623737972223\n",
      "Confusion matrix: \n",
      " [[7297   27    8    0    0   12   12    7    0 1373]\n",
      " [ 511    2    1    0    0    2    2    1    0  234]\n",
      " [ 332    3    0    0    0    3    2    0    0  148]\n",
      " [ 190    1    0    0    0    1    3    0    0  128]\n",
      " [ 194    0    0    0    0    1    1    1    0  165]\n",
      " [ 124    1    0    0    0    0    1    0    0  152]\n",
      " [ 126    1    0    0    0    1    0    0    0  152]\n",
      " [ 120    0    0    0    0    0    0    0    0  196]\n",
      " [ 209    1    0    0    0    1    3    0    0  393]\n",
      " [1136    6    0    0    0    8    5    1    5 7793]]\n",
      "# of training samples:  300\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7161207754657061\n",
      "Confusion matrix: \n",
      " [[7307   47    0    0    0   11   13    0    3 1355]\n",
      " [ 528    4    0    0    0    1    2    0    2  216]\n",
      " [ 343    2    0    0    0    1    4    0    0  138]\n",
      " [ 198    1    0    0    0    0    1    0    1  122]\n",
      " [ 202    0    0    0    0    0    1    0    0  159]\n",
      " [ 130    0    0    0    0    1    1    0    0  146]\n",
      " [ 132    2    0    0    0    0    0    0    0  146]\n",
      " [ 118    0    0    0    0    0    0    0    0  198]\n",
      " [ 217    1    0    0    0    0    3    0    0  386]\n",
      " [1099    2    0    1    0    3   14    0   39 7796]]\n",
      "# of training samples:  400\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7172109778641513\n",
      "Confusion matrix: \n",
      " [[7462   70    5    0    2    2    0    0    3 1192]\n",
      " [ 561    4    2    0    0    0    1    0    0  185]\n",
      " [ 362    4    0    0    0    0    0    0    0  122]\n",
      " [ 221    0    0    0    0    0    1    0    0  101]\n",
      " [ 228    0    0    0    0    0    0    0    1  133]\n",
      " [ 145    0    0    0    0    0    1    1    0  131]\n",
      " [ 150    1    1    0    0    0    0    0    0  128]\n",
      " [ 132    0    0    0    0    0    0    0    0  184]\n",
      " [ 245    1    0    0    0    0    0    0    0  361]\n",
      " [1219    9    3    0    0    0    5   29   24 7665]]\n",
      "# of training samples:  500\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7125657676446888\n",
      "Confusion matrix: \n",
      " [[7381   45    1   22    0    1    2    0    2 1282]\n",
      " [ 544    1    0    0    0    0    0    0    0  208]\n",
      " [ 341    2    0    0    0    0    1    0    0  144]\n",
      " [ 202    0    0    0    0    0    1    0    0  120]\n",
      " [ 207    1    0    1    1    0    0    0    1  151]\n",
      " [ 132    0    0    0    0    0    0    1    0  145]\n",
      " [ 129    1    0    1    0    0    0    0    0  149]\n",
      " [ 123    0    0    2    0    0    0    0    0  191]\n",
      " [ 218    1    0    4    1    0    0    0    0  383]\n",
      " [1213    7    1   48    1    1    3   10   20 7650]]\n",
      "# of training samples:  600\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.714461771815898\n",
      "Confusion matrix: \n",
      " [[7540   18    1   16    0    2    0    0    1 1158]\n",
      " [ 553    1    0    0    0    0    0    0    0  199]\n",
      " [ 369    0    0    0    0    0    0    0    0  119]\n",
      " [ 208    0    0    0    0    1    0    1    0  113]\n",
      " [ 216    0    0    1    0    0    0    0    0  145]\n",
      " [ 126    0    0    0    0    0    0    1    0  151]\n",
      " [ 134    2    0    1    0    0    0    0    0  143]\n",
      " [ 126    1    0    1    0    0    0    0    0  188]\n",
      " [ 232    1    0    5    0    0    0    2    0  367]\n",
      " [1344    6    0   31    0    1    0   39    1 7532]]\n",
      "# of training samples:  700\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7162629757785467\n",
      "Confusion matrix: \n",
      " [[7494   22    0    3    2    0    0    1    3 1211]\n",
      " [ 551    2    0    2    0    0    0    0    0  198]\n",
      " [ 362    1    0    1    0    1    0    0    0  123]\n",
      " [ 203    0    0    0    0    0    1    0    0  119]\n",
      " [ 215    2    0    0    0    0    0    0    0  145]\n",
      " [ 133    0    0    0    0    0    0    0    0  145]\n",
      " [ 135    2    0    0    0    0    0    0    0  143]\n",
      " [ 120    1    0    0    0    0    0    0    0  195]\n",
      " [ 226    1    0    1    0    0    1    0    0  378]\n",
      " [1314   19    0    1    0    0    1    3    1 7615]]\n",
      "# of training samples:  800\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7195335829738826\n",
      "Confusion matrix: \n",
      " [[7524   12    1    6    0    1    0    2    2 1188]\n",
      " [ 553    1    0    0    0    0    0    0    0  199]\n",
      " [ 364    1    1    0    0    0    0    0    0  122]\n",
      " [ 208    0    0    0    0    0    0    1    0  114]\n",
      " [ 212    2    0    0    0    0    0    0    0  148]\n",
      " [ 134    0    0    1    0    0    0    0    0  143]\n",
      " [ 134    2    0    0    0    0    0    0    0  144]\n",
      " [ 124    1    0    0    0    0    0    0    0  191]\n",
      " [ 230    1    0    2    0    0    0    0    0  374]\n",
      " [1279   13    1    7    0    0    0    0    0 7654]]\n",
      "# of training samples:  900\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7209555861022894\n",
      "Confusion matrix: \n",
      " [[7492   10    2    3    2    1    0    1    1 1224]\n",
      " [ 548    0    0    2    0    0    0    0    0  203]\n",
      " [ 360    1    1    3    0    0    0    0    0  123]\n",
      " [ 208    0    0    0    0    0    0    0    0  115]\n",
      " [ 209    0    0    1    0    0    0    0    0  152]\n",
      " [ 133    1    0    1    0    0    0    0    0  143]\n",
      " [ 139    0    0    0    0    0    0    0    0  141]\n",
      " [ 120    2    0    0    0    0    0    0    0  194]\n",
      " [ 231    0    0    2    0    0    0    0    0  374]\n",
      " [1221    3    1   10    0    0    0    2    0 7717]]\n",
      "# of training samples:  1000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7184433805754372\n",
      "Confusion matrix: \n",
      " [[7522    1    1    2    0    0    0    0    3 1207]\n",
      " [ 555    0    0    3    0    0    0    0    0  195]\n",
      " [ 365    0    0    1    0    0    0    0    1  121]\n",
      " [ 206    0    0    0    0    0    0    0    0  117]\n",
      " [ 215    0    0    0    0    0    0    0    0  147]\n",
      " [ 135    0    0    0    0    0    0    0    1  142]\n",
      " [ 136    0    0    0    0    0    0    0    0  144]\n",
      " [ 121    1    0    0    0    0    0    0    0  194]\n",
      " [ 237    0    0    1    0    0    0    0    0  369]\n",
      " [1313    1    1    3    0    0    0    0    1 7635]]\n",
      "# of training samples:  2000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7270227994501588\n",
      "Confusion matrix: \n",
      " [[7547    1    0    0    0    0    0    0    1 1187]\n",
      " [ 545    1    0    0    0    0    0    0    0  207]\n",
      " [ 357    0    0    0    0    0    0    0    0  131]\n",
      " [ 203    0    0    0    0    0    0    0    0  120]\n",
      " [ 216    1    0    0    0    0    0    0    0  145]\n",
      " [ 136    0    0    0    0    0    0    0    0  142]\n",
      " [ 134    0    0    0    0    0    0    0    0  146]\n",
      " [ 119    0    0    0    0    0    0    0    0  197]\n",
      " [ 235    0    0    0    0    0    0    0    1  371]\n",
      " [1160    0    1    0    2    0    0    0    2 7789]]\n",
      "# of training samples:  5000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7341802151964735\n",
      "Confusion matrix: \n",
      " [[7553    1    0    0    0    0    0    0    1 1181]\n",
      " [ 549    0    0    0    0    0    0    0    0  204]\n",
      " [ 355    0    0    0    0    0    0    0    0  133]\n",
      " [ 214    0    0    0    0    0    0    0    0  109]\n",
      " [ 202    0    0    0    1    0    0    0    0  159]\n",
      " [ 132    0    0    0    0    0    0    0    0  146]\n",
      " [ 132    0    0    0    0    0    0    0    0  148]\n",
      " [ 112    0    0    0    0    0    0    0    0  204]\n",
      " [ 219    0    0    0    0    0    0    0    0  388]\n",
      " [1015    2    0    0    0    2    0    0    0 7935]]\n",
      "# of training samples:  10000\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7346068161349955\n",
      "Confusion matrix: \n",
      " [[7582    0    0    0    0    0    1    0    0 1153]\n",
      " [ 549    0    0    0    0    0    0    0    0  204]\n",
      " [ 359    0    0    0    1    0    0    0    0  128]\n",
      " [ 214    0    0    0    0    0    0    0    0  109]\n",
      " [ 209    0    0    0    0    0    0    0    0  153]\n",
      " [ 135    0    0    0    0    0    0    0    0  143]\n",
      " [ 132    0    0    0    0    0    0    0    0  148]\n",
      " [ 115    0    0    0    0    0    0    0    0  201]\n",
      " [ 213    0    0    0    0    0    0    0    0  394]\n",
      " [1036    0    0    0    0    2    0    0    0 7916]]\n",
      "# of training samples:  20000\n",
      "# of validation samples:  21097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.735744418637721\n",
      "Confusion matrix: \n",
      " [[7567    0    0    1    0    0    1    0    0 1167]\n",
      " [ 549    0    0    0    0    0    0    0    0  204]\n",
      " [ 354    0    0    0    1    0    0    0    0  133]\n",
      " [ 211    0    0    0    0    0    0    0    0  112]\n",
      " [ 214    0    0    0    0    0    0    0    0  148]\n",
      " [ 134    0    0    0    0    0    0    0    0  144]\n",
      " [ 131    0    0    0    0    0    0    0    0  149]\n",
      " [ 116    0    0    0    0    0    0    1    0  199]\n",
      " [ 213    0    0    0    0    1    0    0    0  393]\n",
      " [ 997    0    1    0    0    1    0    1    0 7954]]\n",
      "# of training samples:  50000\n",
      "# of validation samples:  21097\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-52cdfbfac701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# of validation samples: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_no_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mno_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mno_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#first column of y: tree cover label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_no_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Benchmark classification of Sentinel-2 data using sklearn RandomForestClassifier\n",
    "\n",
    "# Load libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import ElasticNet\n",
    "#from sklearn.linear_model import ElasticNetCV\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(x_train)\n",
    "#x_train_tr = scaler.transform(x_train)\n",
    "#x_validate_tr = scaler.transform(x_validate)\n",
    "\n",
    "# Make scorer\n",
    "#acc_score=make_scorer(accuracy_score)\n",
    "\n",
    "# Train/fit the model and predict results for different numbers of samples\n",
    "#no_samples_array = [100, 200, 300]\n",
    "no_samples_array = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 5000, 10000, 20000, 60000]\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=1000, bootstrap=False, class_weight='balanced')\n",
    "\n",
    "for no_samples in no_samples_array:\n",
    "    print(\"# of training samples: \", no_samples)\n",
    "    \n",
    "    #val_no_samples = min(int(no_samples/3), no_records_validate)\n",
    "    val_no_samples = no_records_validate\n",
    "    print(\"# of validation samples: \", val_no_samples)\n",
    "    \n",
    "    clf.fit(x_train[:no_samples, :],y_train[:no_samples,0]) #first column of y: tree cover label\n",
    "    y_pred = clf.predict(x_validate[:val_no_samples,:])\n",
    "\n",
    "    # evaluate accuracy\n",
    "    acc = clf.score(x_validate[:val_no_samples,:], y_validate[:val_no_samples,0])\n",
    "    accuracies.append(acc)\n",
    "    print(\"Accuracy score: \", acc)\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_validate[:val_no_samples,0], y_pred)\n",
    "    confusion_matrices.append(conf_mat)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6755936863061098, 0.7153623737972223, 0.7161207754657061, 0.7172109778641513, 0.7125657676446888, 0.714461771815898, 0.7162629757785467, 0.7195335829738826, 0.7209555861022894, 0.7184433805754372, 0.7270227994501588, 0.7341802151964735, 0.7346068161349955, 0.735744418637721]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benchmark classification of Sentinel-2 data using sklearn RandomForestClassifier\n",
    "## with preprocessing of data\n",
    "\n",
    "no_pixels = 7*7\n",
    "no_channels = 10\n",
    "\n",
    "# Preprocess data by reordering pixels in all 10 channels to the order of green+blue channel pixels\n",
    "# by value, i.e. \"greenest+bluest\" pixel first, \"least green+blue\" last\n",
    "\n",
    "# Training data\n",
    "x_train_r = np.zeros(x_train.shape)\n",
    "\n",
    "#for i in range(x_train.shape[0]):\n",
    "for i in range(300):\n",
    "    # Find order of indices by of the green channel by value\n",
    "    g = x_train[i, bands.index('B3')*no_pixels : (bands.index('B3')+1)*(no_pixels)] #green channel = B3\n",
    "    b = x_train[i, bands.index('B2')*no_pixels : (bands.index('B2')+1)*(no_pixels)] #blue channel = B2\n",
    "    gb = np.add(g,b)\n",
    "    sorted_indices = np.argsort(gb)\n",
    "    for j in range(no_channels):\n",
    "        for k in range(no_pixels):\n",
    "            x_train_r[i,(j*no_pixels)+k] = x_train[i,(j*no_pixels)+sorted_indices[k]]\n",
    "            \n",
    "# Validation data\n",
    "x_validate_r = np.zeros(x_validate.shape)\n",
    "\n",
    "#for i in range(x_validate.shape[0]):\n",
    "for i in range(300):\n",
    "    # Find order of indices by of the green channel by value\n",
    "    g = x_validate[i, bands.index('B3')*no_pixels : (bands.index('B3')+1)*(no_pixels)] #green channel = B3\n",
    "    b = x_train[i, bands.index('B2')*no_pixels : (bands.index('B2')+1)*(no_pixels)] #blue channel = B2\n",
    "    gb = np.add(g,b)\n",
    "    sorted_indices = np.argsort(gb)\n",
    "    for j in range(no_channels):\n",
    "        for k in range(no_pixels):\n",
    "            x_validate_r[i,j*no_pixels + k] = x_validate[i,j*no_pixels + sorted_indices[k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID : ['GLU0340923']\n",
      "Tree cover label : 0\n",
      "All cover labels : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display one train image after reordering\n",
    "image_id = 118\n",
    "print(\"ID :\", id_train[image_id])\n",
    "print(\"Tree cover label :\", y_train[image_id,0])\n",
    "print(\"All cover labels :\", y_train[image_id,:])\n",
    "\n",
    "rgbArray_r = np.zeros((7,7,3))\n",
    "rgbArray_r[..., 0] = x_train_r[image_id, bands.index('B4')*no_pixels:(bands.index('B4') + 1)*(no_pixels)].reshape((7,7))\n",
    "rgbArray_r[..., 1] = x_train_r[image_id, bands.index('B3')*no_pixels:(bands.index('B3') + 1)*(no_pixels)].reshape((7,7))\n",
    "rgbArray_r[..., 2] = x_train_r[image_id, bands.index('B2')*no_pixels:(bands.index('B2') + 1)*(no_pixels)].reshape((7,7))\n",
    "rgbArray_r[rgbArray_r > 0.3] = 0.3\n",
    "rgbArray_r = rgbArray_r / 0.3\n",
    "\n",
    "rgbArray = np.zeros((7,7,3))\n",
    "rgbArray[..., 0] = x_train[image_id, bands.index('B4')*no_pixels:(bands.index('B4') + 1)*(no_pixels)].reshape((7,7))\n",
    "rgbArray[..., 1] = x_train[image_id, bands.index('B3')*no_pixels:(bands.index('B3') + 1)*(no_pixels)].reshape((7,7))\n",
    "rgbArray[..., 2] = x_train[image_id, bands.index('B2')*no_pixels:(bands.index('B2') + 1)*(no_pixels)].reshape((7,7))\n",
    "rgbArray[rgbArray > 0.3] = 0.3\n",
    "rgbArray = rgbArray / 0.3\n",
    "#print(rgbArray)\n",
    "\n",
    "images = [rgbArray, rgbArray_r]\n",
    "\n",
    "for ima in images:\n",
    "    plt.figure()\n",
    "    plt.imshow(ima, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples:  100\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.6777740911030005\n",
      "Confusion matrix: \n",
      " [[6958   48    6  156    5    6   89  167   10 1291]\n",
      " [ 485    7    1   15    2    0   30   18    2  193]\n",
      " [ 299    6    0   10    0    0   14   11    2  146]\n",
      " [ 172    1    0    2    0    0   11    7    0  130]\n",
      " [ 166    0    0   11    1    1    9   12    0  162]\n",
      " [ 110    3    0    6    0    1    9    4    0  145]\n",
      " [ 114    3    0    7    0    2    3    3    1  147]\n",
      " [ 105    2    0    7    0    1   11    4    0  186]\n",
      " [ 204    5    0    7    0    1   11    5    1  373]\n",
      " [1248   61    0  174    0    2  101   22   24 7322]]\n",
      "# of training samples:  200\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7147935725458596\n",
      "Confusion matrix: \n",
      " [[7295    3    2    0    0    5   22    0    2 1407]\n",
      " [ 509    2    0    0    0    1    3    0    0  238]\n",
      " [ 330    0    0    0    0    1    4    0    0  153]\n",
      " [ 189    0    0    0    0    0    3    0    0  131]\n",
      " [ 195    0    0    0    0    1    1    0    0  165]\n",
      " [ 121    0    0    0    0    0    4    0    0  153]\n",
      " [ 120    0    1    0    0    1    0    0    0  158]\n",
      " [ 115    0    0    0    0    1    1    0    1  198]\n",
      " [ 203    0    0    0    0    0    4    0    0  400]\n",
      " [1150    0    0    0    0    1   18    0    2 7783]]\n",
      "# of training samples:  300\n",
      "# of validation samples:  21097\n",
      "Accuracy score:  0.7092477603450728\n",
      "Confusion matrix: \n",
      " [[7143   95    0    0   55   22   16    0    0 1405]\n",
      " [ 508    9    0    0    9    1    4    0    0  222]\n",
      " [ 313    7    1    0   13    1    4    0    1  148]\n",
      " [ 185    4    0    0    7    1    2    0    1  123]\n",
      " [ 188    4    0    0    3    1    4    0    1  161]\n",
      " [ 121    3    0    0    3    1    2    0    0  148]\n",
      " [ 118    4    2    0    3    0    0    0    0  153]\n",
      " [ 108    2    0    0    1    1    0    0    1  203]\n",
      " [ 197    3    0    0    3    1    5    0    1  397]\n",
      " [1064   20    0    0   29    6   18    0   12 7805]]\n",
      "# of training samples:  400\n",
      "# of validation samples:  21097\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-1c76e7479610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# evaluate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0macc_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validate_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_no_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_no_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0maccuracies_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \"\"\"\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    667\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[1;32m    668\u001b[0m                                             lock)\n\u001b[0;32m--> 669\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \"\"\"\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         attrs = [v for v in vars(estimator)\n\u001b[0m\u001b[1;32m    964\u001b[0m                  if v.endswith(\"_\") and not v.startswith(\"__\")]\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         attrs = [v for v in vars(estimator)\n\u001b[0m\u001b[1;32m    964\u001b[0m                  if v.endswith(\"_\") and not v.startswith(\"__\")]\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Classify for benchmarking values\n",
    "\n",
    "no_samples_array = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 5000, 10000, 20000, 60000]\n",
    "accuracies_r = []\n",
    "confusion_matrices_r = []\n",
    "\n",
    "clf_r = RandomForestClassifier(random_state=0, n_estimators=10000, bootstrap=False, class_weight='balanced')\n",
    "\n",
    "for no_samples in no_samples_array:\n",
    "    print(\"# of training samples: \", no_samples)\n",
    "    \n",
    "    #val_no_samples = min(int(no_samples/3), no_records_validate)\n",
    "    val_no_samples = no_records_validate\n",
    "    print(\"# of validation samples: \", val_no_samples)\n",
    "    \n",
    "    clf_r.fit(x_train_r[:no_samples, :],y_train[:no_samples,0]) #first column of y: tree cover label\n",
    "    y_pred = clf_r.predict(x_validate_r[:val_no_samples,:])\n",
    "\n",
    "    # evaluate accuracy\n",
    "    acc_r = clf_r.score(x_validate_r[:val_no_samples,:], y_validate[:val_no_samples,0])\n",
    "    accuracies_r.append(acc_r)\n",
    "    print(\"Accuracy score: \", acc_r)\n",
    "    \n",
    "    conf_mat_r = confusion_matrix(y_validate[:val_no_samples,0], y_pred)\n",
    "    confusion_matrices_r.append(conf_mat_r)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hr/r8bv52hn6sj5ny319b4nfg0h0000gn/T/tmp_7ll7twr', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For now, we only support Dense column with rank of 1, but column `B11` got: (7, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-fd871821adf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mn_batches_per_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalidate_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1162\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1192\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1194\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1195\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1900\u001b[0m           \u001b[0mclosed_form_grad_and_hess_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosed_form\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m           \u001b[0mweight_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m           train_in_memory=train_in_memory)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m     super(BoostedTreesClassifier, self).__init__(\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py\u001b[0m in \u001b[0;36m_bt_model_fn\u001b[0;34m(features, labels, mode, head, feature_columns, tree_hparams, n_batches_per_layer, config, closed_form_grad_and_hess_fn, example_id_column_name, weight_column, train_in_memory, name)\u001b[0m\n\u001b[1;32m   1194\u001b[0m       input_feature_list = _get_transformed_features(features,\n\u001b[1;32m   1195\u001b[0m                                                      \u001b[0msorted_feature_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                                                      bucket_boundaries_dict)\n\u001b[0m\u001b[1;32m   1197\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mexample_id_column_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0mexample_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_id_column_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py\u001b[0m in \u001b[0;36m_get_transformed_features\u001b[0;34m(features, sorted_feature_columns, bucket_boundaries_dict)\u001b[0m\n\u001b[1;32m    164\u001b[0m   return _get_transformed_features_and_merge_with_previously_transformed(\n\u001b[1;32m    165\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_feature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_feature_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       bucket_boundaries_dict)\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ee/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py\u001b[0m in \u001b[0;36m_get_transformed_features_and_merge_with_previously_transformed\u001b[0;34m(features, sorted_feature_columns, all_sorted_columns, bucket_boundaries_dict, already_transformed_features)\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError('For now, we only support Dense column with rank of '\n\u001b[1;32m    233\u001b[0m                          '1, but column `{}` got: {}'.format(\n\u001b[0;32m--> 234\u001b[0;31m                              source_name, column.variable_shape))\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0munstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbucket_boundaries_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: For now, we only support Dense column with rank of 1, but column `B11` got: (7, 7)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GLU0452795']\n"
     ]
    }
   ],
   "source": [
    "print(id_train[118])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
